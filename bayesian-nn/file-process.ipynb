{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c212b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using XLSX\n",
    "using Statistics\n",
    "using Glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e777e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0974fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=\n",
    "This function removes the unnecessary columns for the input of BNN\n",
    "This function also writes the processed data into its respective CSV file\n",
    "=#\n",
    "function process(otu, res, res_idx, level, feature_sel, score)\n",
    "    \n",
    "    if res_idx == 1\n",
    "        selected_feature = filter(row -> !(row.B != score), feature_sel)\n",
    "    elseif res_idx == 2\n",
    "        selected_feature = filter(row -> !(row.C != score), feature_sel)\n",
    "    elseif res_idx  == 3\n",
    "        selected_feature = filter(row -> !(row.D != score), feature_sel)\n",
    "    elseif res_idx == 4\n",
    "        selected_feature = filter(row -> !(row.E != score), feature_sel)\n",
    "    elseif res_idx == 5\n",
    "        selected_feature = filter(row -> !(row.F != score), feature_sel)\n",
    "    else\n",
    "        selected_feature = filter(row -> !(row.G != score), feature_sel)\n",
    "    end\n",
    "   \n",
    "    if score == 0 \n",
    "        if res_idx == 1\n",
    "            three_score = filter(row -> !(row.B != 3), feature_sel)\n",
    "        elseif res_idx == 2\n",
    "            three_score = filter(row -> !(row.C != 3), feature_sel)\n",
    "        elseif res_idx  == 3\n",
    "            three_score = filter(row -> !(row.D != 3), feature_sel)\n",
    "        elseif res_idx == 4\n",
    "            three_score = filter(row -> !(row.E != 3), feature_sel)\n",
    "        elseif res_idx == 5\n",
    "            three_score = filter(row -> !(row.F != 3), feature_sel)\n",
    "        else\n",
    "            three_score = filter(row -> !(row.G != 3), feature_sel)\n",
    "        end\n",
    "        three_num = size(three_score)[1]\n",
    "        if three_num <= size(selected_feature)[1]\n",
    "            feature_name = selected_feature[1:three_num, 1]\n",
    "        else\n",
    "            feature_name = selected_feature[:, 1]\n",
    "        end\n",
    "    else\n",
    "        feature_name = selected_feature[:, 1]\n",
    "    end\n",
    "    \n",
    "    \n",
    "    ###################################################################################\n",
    "    # WARNING: VERY WERID FEATURE NAME CHANGE, WILL REMOVE AFTER ADDRESSING THE ISSUE #\n",
    "    ###################################################################################\n",
    "    for i in 1:length(feature_name)\n",
    "        if feature_name[i][1] == 'X' && (Int(feature_name[i][2]) in 46:57)\n",
    "            feature_name[i] = replace(feature_name[i], \"X\" => \"\")\n",
    "        end\n",
    "    end\n",
    "    ####################################################################################\n",
    "    \n",
    "    id = otu[:, 1]\n",
    "    otu = otu[:, feature_name]\n",
    "    otu = convert.(Float64, otu)\n",
    "    otu = normalize(otu)\n",
    "    otu = hcat(id, otu)\n",
    "    rename!(otu,:x1 => :Column1)\n",
    "    \n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(1, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/otu_data/non_augumented/$score/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "\n",
    "    return feature_name\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa31e8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize(otu) \n",
    "    for i in 1:size(otu)[1]\n",
    "        row_sum = sum(otu[i,:])\n",
    "        for j in 1:size(otu)[2]\n",
    "            convert(Float64, otu[i, j])\n",
    "            if row_sum == 0\n",
    "                otu[i,j] = 0\n",
    "            else\n",
    "                otu[i,j] = otu[i,j] / row_sum\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return otu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2161882f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restruct_data (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function restruct_data(level)\n",
    "    data = CSV.read(\"../raw-data/Y1_F_$level.csv\", DataFrame)\n",
    "    data = data[data[:,2] .!= \"NA\", :]\n",
    "    nrow = size(data)[1]\n",
    "    ###################################################################################\n",
    "    # WARNING: VERY WERID FEATURE NAME CHANGE, WILL REMOVE AFTER ADDRESSING THE ISSUE #\n",
    "    ###################################################################################\n",
    "    for i in 1:nrow\n",
    "        data[i,2] = replace(data[i,2], \"-\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \" \" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"(\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \")\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"/\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"[\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"]\" => \".\")\n",
    "    end\n",
    "    ####################################################################################\n",
    "    ncol = size(data)[2]\n",
    "    df = data[:, 3:ncol]\n",
    "    colnames = names(df)\n",
    "    df[!, :id] = data[:,2]\n",
    "    df1 = stack(df, colnames)\n",
    "    df_new = unstack(df1, :variable, :id, :value)\n",
    "    data = rename!(df_new, :variable => :Column1)\n",
    "    data = data[completecases(data), :]\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "094cf439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#= \n",
    "This function load the filtered otu and responses \n",
    "=#\n",
    "function load_otu(level, score)\n",
    "    # load important feature table\n",
    "    feature_selection = DataFrame(XLSX.readtable(\"../processed-data/important_features_score.xlsx\"\n",
    "            , \"$level\", \"A:G\", header=false))\n",
    "    \n",
    "    # load raw OTU count data\n",
    "    otu = restruct_data(level)\n",
    "    \n",
    "    # load all responses\n",
    "    response_path = \"../processed-data/response\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "  \n",
    "    for j in 1:length(response)\n",
    "        process(otu, response[j], j, level, feature_selection, score)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c959c337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_all_OTU (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_all_OTU(level, aug)\n",
    "    # load all filtered data in one level folder\n",
    "    otu_path = \"../processed-data/otu_data/original/$aug/$level\"\n",
    "    otu_files = glob(\"*.csv\", otu_path)\n",
    "    otu = DataFrame.(CSV.File.(otu_files))\n",
    "\n",
    "    # load all responses\n",
    "    response_path = \"../processed-data/response/$aug\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files))\n",
    "\n",
    "    # pass them to process and write to new CSVs\n",
    "    for i in 1:length(otu)\n",
    "        for j in 1:length(response)\n",
    "            process_all_otu(otu[i], response[j], i, j, level, aug)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc64087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_all_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_all_otu(otu, res, otu_idx, res_idx, level, aug)\n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(otu_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/otu_data/all_otu/$aug/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9dfb11b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha_process (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function alpha_process(alpha, res, alpha_idx, res_idx, level)\n",
    "    alpha = alpha[:, Not(1)]\n",
    "    rename!(alpha,:Link_ID => :Column1)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(alpha, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1:2)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(alpha_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_index_data/non_augumented/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80798b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha(level)\n",
    "    alpha_path = \"../processed-data/alpha_index_data/original/$level\"\n",
    "    alpha_files = glob(\"*.csv\", alpha_path);\n",
    "    alpha = DataFrame.(CSV.File.(alpha_files));\n",
    "    \n",
    "    # load all responses\n",
    "    response_path = \"../processed-data/response\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(alpha)\n",
    "        for j in 1:length(response)\n",
    "            alpha_process(alpha[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb6b6c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_process (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function other_process(file, res, pred_idx, res_idx, pred)\n",
    "    file = file[completecases(file), :]\n",
    "    file = file[:, Not(1)]\n",
    "    rename!(file,:Link_ID => :Column1)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(file, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1:2)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/$pred/non_augumented/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b881f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_other (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_other(pred)\n",
    "    path = \"../processed-data/$pred/original\"\n",
    "    files = glob(\"*.csv\", path);\n",
    "    data = DataFrame.(CSV.File.(files));\n",
    "    \n",
    "    # load all responses\n",
    "    response_path = \"../processed-data/response\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            other_process(data[i], response[j], i, j, pred)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39eeff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n"
     ]
    }
   ],
   "source": [
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"]\n",
    "\n",
    "# get all files for OTUs\n",
    "for i in 1:length(all_level)\n",
    "    for j in 0:3\n",
    "        load_otu(all_level[i], j)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25ccd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5096cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files for alpha diversity index\n",
    "for i in 1:length(all_level)\n",
    "    load_alpha(all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4aa49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_other(\"soil_chemistry_data\")\n",
    "load_other(\"disease_suppression_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12753b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n",
      "270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2-element Vector{Tuple{Int64, Int64}}:\n",
       " (1, 89)\n",
       " (0, 110)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CSV.read(\"../processed-data/otu_data/all_otu/non-augumented/Order/full-data/1_3.csv\", DataFrame)\n",
    "b = CSV.read(\"../processed-data/otu_data/all_otu/augumented/Family/train-test-split/1_3_test.csv\", DataFrame)\n",
    "println(size(a)[2]-1)\n",
    "println(size(b)[2]-1)\n",
    "pert = [(i, count(==(i), b[:,size(b)[2]])) for i in unique(b[:,size(b)[2]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ee3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\"]\n",
    "# get all files for OTUs\n",
    "for i in 1:length(all_level)\n",
    "    load_all_OTU(all_level[i], \"augumented\")\n",
    "end\n",
    "for i in 1:length(all_level)\n",
    "    load_all_OTU(all_level[i], \"non-augumented\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
