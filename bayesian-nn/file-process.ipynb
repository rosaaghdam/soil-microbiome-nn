{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c212b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using XLSX\n",
    "using Statistics\n",
    "using Glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe83b9b",
   "metadata": {},
   "source": [
    "# Generic Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2aa536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_response (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_response(aug)\n",
    "    response_path = \"../processed-data/response/$aug/\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    return response\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc9cb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_generic_data (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_generic_data(data, level)\n",
    "    if level != \"null\"\n",
    "        path = \"../processed-data/$data/original/$level\"\n",
    "    else\n",
    "        path = \"../processed-data/$data/original\"\n",
    "    end\n",
    "    files = glob(\"*.csv\", path);\n",
    "    data = DataFrame.(CSV.File.(files))\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2a5f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drop_miss (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function drop_miss(file) \n",
    "    file = file[completecases(file), :]\n",
    "    file = file[:, Not(1)]\n",
    "    rename!(file,:Link_ID => :Column1)\n",
    "    return file\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "608eed03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "select_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function select_otu(otu, res, res_idx, level, feature_sel, score)\n",
    "    if res_idx == 1\n",
    "        selected_feature = filter(row -> !(row.B != score), feature_sel)\n",
    "    elseif res_idx == 2\n",
    "        selected_feature = filter(row -> !(row.C != score), feature_sel)\n",
    "    elseif res_idx  == 3\n",
    "        selected_feature = filter(row -> !(row.D != score), feature_sel)\n",
    "    elseif res_idx == 4\n",
    "        selected_feature = filter(row -> !(row.E != score), feature_sel)\n",
    "    elseif res_idx == 5\n",
    "        selected_feature = filter(row -> !(row.F != score), feature_sel)\n",
    "    else\n",
    "        selected_feature = filter(row -> !(row.G != score), feature_sel)\n",
    "    end\n",
    "   \n",
    "    if score == 0 \n",
    "        if res_idx == 1\n",
    "            three_score = filter(row -> !(row.B != 3), feature_sel)\n",
    "        elseif res_idx == 2\n",
    "            three_score = filter(row -> !(row.C != 3), feature_sel)\n",
    "        elseif res_idx  == 3\n",
    "            three_score = filter(row -> !(row.D != 3), feature_sel)\n",
    "        elseif res_idx == 4\n",
    "            three_score = filter(row -> !(row.E != 3), feature_sel)\n",
    "        elseif res_idx == 5\n",
    "            three_score = filter(row -> !(row.F != 3), feature_sel)\n",
    "        else\n",
    "            three_score = filter(row -> !(row.G != 3), feature_sel)\n",
    "        end\n",
    "        three_num = size(three_score)[1]\n",
    "        if three_num <= size(selected_feature)[1]\n",
    "            feature_name = selected_feature[1:three_num, 1]\n",
    "        else\n",
    "            feature_name = selected_feature[:, 1]\n",
    "        end\n",
    "    else\n",
    "        feature_name = selected_feature[:, 1]\n",
    "    end\n",
    "    \n",
    "    \n",
    "    ###################################################################################\n",
    "    # WARNING: VERY WERID FEATURE NAME CHANGE, WILL REMOVE AFTER ADDRESSING THE ISSUE #\n",
    "    ###################################################################################\n",
    "    for i in 1:length(feature_name)\n",
    "        if feature_name[i][1] == 'X' && (Int(feature_name[i][2]) in 46:57)\n",
    "            feature_name[i] = replace(feature_name[i], \"X\" => \"\")\n",
    "        end\n",
    "    end\n",
    "    ####################################################################################\n",
    "    \n",
    "    id = otu[:, 1]\n",
    "    otu = otu[:, feature_name]\n",
    "    otu = convert.(Float64, otu)\n",
    "    otu = normalize(otu)\n",
    "    otu = hcat(id, otu)\n",
    "    rename!(otu,:x1 => :Column1)\n",
    "    return otu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "338246b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize(otu) \n",
    "    for i in 1:size(otu)[1]\n",
    "        row_sum = sum(otu[i,:])\n",
    "        for j in 1:size(otu)[2]\n",
    "            convert(Float64, otu[i, j])\n",
    "            if row_sum == 0\n",
    "                otu[i,j] = 0\n",
    "            else\n",
    "                otu[i,j] = otu[i,j] / row_sum\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return otu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b39506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restruct_data (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function restruct_data(level)\n",
    "    data = CSV.read(\"../raw-data/Y1_F_$level.csv\", DataFrame)\n",
    "    data = data[data[:,2] .!= \"NA\", :]\n",
    "    nrow = size(data)[1]\n",
    "    ###################################################################################\n",
    "    # WARNING: VERY WERID FEATURE NAME CHANGE, WILL REMOVE AFTER ADDRESSING THE ISSUE #\n",
    "    ###################################################################################\n",
    "    for i in 1:nrow\n",
    "        data[i,2] = replace(data[i,2], \"-\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \" \" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"(\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \")\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"/\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"[\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"]\" => \".\")\n",
    "    end\n",
    "    ####################################################################################\n",
    "    ncol = size(data)[2]\n",
    "    df = data[:, 3:ncol]\n",
    "    colnames = names(df)\n",
    "    df[!, :id] = data[:,2]\n",
    "    df1 = stack(df, colnames)\n",
    "    df_new = unstack(df1, :variable, :id, :value)\n",
    "    data = rename!(df_new, :variable => :Column1)\n",
    "    data = data[completecases(data), :]\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d095c3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aug_norm (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function aug_norm(otu)\n",
    "    id = otu[:, 1]\n",
    "    otu = otu[:, Not(1)]\n",
    "    otu = convert.(Float64, otu)\n",
    "    otu = normalize(otu)\n",
    "    otu = hcat(id, otu)\n",
    "    rename!(otu,:x1 => :Column1)\n",
    "    return otu\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c103fc8",
   "metadata": {},
   "source": [
    "# Augmented OTU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f43810d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_augment_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_augment_otu(level)\n",
    "    otu = CSV.read(\"../processed-data/data-augmentation/otu/$level.csv\", DataFrame)\n",
    "    otu = aug_norm(otu)\n",
    "    \n",
    "    response_path = \"../processed-data/data-augmentation/response\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    for j in 1:length(response)\n",
    "        process_augment_otu(otu, response[j], j, level, \"train\")\n",
    "    end\n",
    "    \n",
    "    otu = CSV.read(\"../processed-data/data-augmentation/otu/$level.csv\", DataFrame)\n",
    "    otu = aug_norm(otu)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37293709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_augment_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_augment_otu(otu, res, res_idx, level, train)\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(1, \"_\", res_idx, \"_\", train)\n",
    "    CSV.write(\"../processed-data/all_otu_augmented/$level/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f777876a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_aug_train (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_aug_train(level, response, response_num)\n",
    "    filename = string(level, \"_test\")\n",
    "    data = CSV.read(\"../processed-data/all_otu_original/$response/train-test-split/$filename.csv\", DataFrame)\n",
    "    data = data[:, Not(1)]\n",
    "    label = data[:, size(data)[2]]\n",
    "    data = data[:, Not(size(data)[2])]\n",
    "    data = convert.(Float64, data)\n",
    "    data = normalize(data)\n",
    "    data = hcat(data, label)\n",
    "    mat = Matrix(data)\n",
    "    filename = string(1, \"_\", response_num, \"_test\")\n",
    "    CSV.write(\"../processed-data/all_otu_augmented/$level/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c23ec",
   "metadata": {},
   "source": [
    "# selected OTU\n",
    "Read all raw OTU counts -> restruct it -> select features by Rosa's selection table -> normalize by row sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0974fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process(otu, res, res_idx, level, feature_sel, score)\n",
    "    otu = select_otu(otu, res, res_idx, level, feature_sel, score)\n",
    "\n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(1, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/otu_selection/$score/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "094cf439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_otu(level, score)\n",
    "    # load important feature table\n",
    "    feature_selection = DataFrame(XLSX.readtable(\"../processed-data/otu_selection/important_features_score.xlsx\"\n",
    "            , \"$level\", \"A:G\", header=false))\n",
    "    \n",
    "    # load raw OTU count data\n",
    "    otu = restruct_data(level)\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "  \n",
    "    for j in 1:length(response)\n",
    "        process(otu, response[j], j, level, feature_selection, score)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db834ef",
   "metadata": {},
   "source": [
    "# All OTU -> augmented & non-augmented\n",
    "load all filtered normalizaed OTU by Rosa -> join with response -> save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c959c337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_all_OTU (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_all_OTU(level, aug)\n",
    "    if aug == \"augmented\"\n",
    "        otu_path = \"../processed-data/all_otu_augmented/original/$level\"\n",
    "    else\n",
    "        otu_path = \"../processed-data/all_otu_non_augmented/original/$level\"\n",
    "    end\n",
    "    \n",
    "    otu_files = glob(\"*.csv\", otu_path)\n",
    "    otu = DataFrame.(CSV.File.(otu_files))\n",
    "\n",
    "    response = load_response(aug)\n",
    "\n",
    "    for i in 1:length(otu)\n",
    "        for j in 1:length(response)\n",
    "            process_all_otu(otu[i], response[j], i, j, level, aug)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc64087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_all_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_all_otu(otu, res, otu_idx, res_idx, level, aug)\n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(otu_idx, \"_\", res_idx)\n",
    "    if aug == \"augmented\"\n",
    "        CSV.write(\"../processed-data/all_otu_augmented/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    else\n",
    "        CSV.write(\"../processed-data/all_otu_non_augmented/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9f5e0",
   "metadata": {},
   "source": [
    "# All alpha diversity indices\n",
    "load all 5 levels of alpha diversity indices with 7 scaling methods -> join with response -> write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfb11b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha_process (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function alpha_process(alpha, res, alpha_idx, res_idx, level)\n",
    "    alpha = drop_miss(alpha)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(alpha, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(alpha_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_index_data/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80798b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha(level)\n",
    "    alpha = load_generic_data(\"alpha_index_data\", level)\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(alpha)\n",
    "        for j in 1:length(response)\n",
    "            alpha_process(alpha[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469560c",
   "metadata": {},
   "source": [
    "# Soil Chemistry & disease suppression\n",
    "load soil chemistry and disease suppression with 6 scaling methods -> join with responses -> write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb6b6c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_process (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function other_process(file, res, pred_idx, res_idx, pred)\n",
    "    file = drop_miss(file)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(file, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/$pred/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b881f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_other (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_other(pred)\n",
    "    data = load_generic_data(pred, \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            other_process(data[i], response[j], i, j, pred)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e888b1",
   "metadata": {},
   "source": [
    "# Soil Chemistry + Disease Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "637440a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_soil_disease()\n",
    "    data1 = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    data2 = load_generic_data(\"disease_suppression_data\", \"null\")\n",
    "    \n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data1)\n",
    "        for j in 1:length(response)\n",
    "            process_soil_disease(data1[i], data2[i], response[j], i, j)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5679dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_soil_disease(file1, file2, res, pred_idx, res_idx)\n",
    "    file1 = drop_miss(file1)\n",
    "    file2 = drop_miss(file2)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(file1, file2, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/soil_disease/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490da7db",
   "metadata": {},
   "source": [
    "# Alpha Diversity Indices + Soil Chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bcecc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha_soil (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha_soil(level)\n",
    "    alpha = load_generic_data(\"alpha_index_data\", level);\n",
    "    data = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            process_alpha_soil(alpha[i],data[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bab2cdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_alpha_soil (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_alpha_soil(alpha, file, res, pred_idx, res_idx, level)\n",
    "    alpha = drop_miss(alpha)\n",
    "    file = drop_miss(file)\n",
    "    \n",
    "    data = innerjoin(alpha, file, res, on = :Column1)\n",
    "    data = data[:, Not(1)]\n",
    "   \n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_soil/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d760621",
   "metadata": {},
   "source": [
    "# Alpha Diversity Indices + Soil Chemistry + Disease Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "374c26af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha_soil_disease(level)\n",
    "    alpha = load_generic_data(\"alpha_index_data\", level);\n",
    "    data1 = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    data2 = load_generic_data(\"disease_suppression_data\", \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data1)\n",
    "        for j in 1:length(response)\n",
    "            process_alpha_soil_disease(alpha[i],data1[i], data2[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a881cde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_alpha_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_alpha_soil_disease(alpha, file1, file2, res, pred_idx, res_idx, level)\n",
    "    alpha = drop_miss(alpha)\n",
    "    file1 = drop_miss(file1)\n",
    "    file2 = drop_miss(file2)\n",
    "    \n",
    "    data = innerjoin(alpha, file1, file2, res, on = :Column1)\n",
    "    data = data[:, Not(1)]\n",
    "   \n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_soil_disease/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420ce4e",
   "metadata": {},
   "source": [
    "# OTU-Score=3 + Soil & OTU-Score=3 + disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd70be72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu_other (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_otu_other(data_name, level)\n",
    "    # load important feature table\n",
    "    feature_selection = DataFrame(XLSX.readtable(\"../processed-data/otu_selection/important_features_score.xlsx\"\n",
    "            , \"$level\", \"A:G\", header=false))\n",
    "    \n",
    "    # load raw OTU count data\n",
    "    otu = restruct_data(level)\n",
    "    data = load_generic_data(data_name, \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            otu_other_process(otu, data[i], response[j], i, j, level, feature_selection, data_name)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "853f43e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "otu_other_process (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function otu_other_process(otu, file, res, pred_idx, res_idx, level, feature_sel, dataName)\n",
    "    otu = select_otu(otu, res, res_idx, level, feature_sel, 3)\n",
    "    file = drop_miss(file)\n",
    "    \n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, file, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    if dataName == \"soil_chemistry_data\"\n",
    "        CSV.write(\"../processed-data/otu_soil/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    else\n",
    "        CSV.write(\"../processed-data/otu_disease/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edccdd3",
   "metadata": {},
   "source": [
    "# OTU-Score=3 + Soil + Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03af3cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_otu_soil_disease(level)\n",
    "    # load important feature table\n",
    "    feature_selection = DataFrame(XLSX.readtable(\"../processed-data/otu_selection/important_features_score.xlsx\"\n",
    "            , \"$level\", \"A:G\", header=false))\n",
    "    \n",
    "    # load raw OTU count data\n",
    "    otu = restruct_data(level)\n",
    "    data1 = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    data2 = load_generic_data(\"disease_suppression_data\", \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data1)\n",
    "        for j in 1:length(response)\n",
    "            combined_process(otu, data1[i], data2[i], response[j], i, j, level, feature_selection)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcde6171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combined_process (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function combined_process(otu, file1, file2, res, pred_idx, res_idx, level, feature_sel)\n",
    "    otu = select_otu(otu, res, res_idx, level, feature_sel, 3)\n",
    "    file1 = drop_miss(file1)\n",
    "    file2 = drop_miss(file2)\n",
    "    \n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, file1, file2, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/otu_soil_disease/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057addd",
   "metadata": {},
   "source": [
    "# All loading function calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "39eeff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#                         Load OTU selection                           #\n",
    "########################################################################\n",
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"]\n",
    "\n",
    "# get all files for OTUs\n",
    "for i in 1:length(all_level)\n",
    "    for j in 0:3\n",
    "        load_otu(all_level[i], j)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "082111c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#                            Load Raw OTU                              #\n",
    "########################################################################\n",
    "for i in 1:length(all_level)\n",
    "    load_raw_otu(all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5096cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#                      Load Alpha Diversity Indices                    #\n",
    "########################################################################\n",
    "for i in 1:length(all_level)\n",
    "    load_alpha(all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c4aa49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#             Load Soil chemistry and disease suppression              #\n",
    "########################################################################\n",
    "load_other(\"soil_chemistry_data\")\n",
    "load_other(\"disease_suppression_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22ee3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#           Load Full OTU for both augmented and non_augmented         #\n",
    "########################################################################\n",
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\"]\n",
    "all_res = [\"no_tuber_scab\", \"no_tuber_scabpit\", \"no_tuber_scabsuper\", \"yield_per_meter\", \"yield_per_plant\", \"pctg_black_scurf\"]\n",
    "# get all files for OTUs\n",
    "#=\n",
    "for i in 1:length(all_level)\n",
    "    load_augment_otu(all_level[i])\n",
    "end\n",
    "=#\n",
    "for i in 1:length(all_level)\n",
    "    for j in 1:length(all_res)\n",
    "        get_aug_train(all_level[i], all_res[j], j)\n",
    "    end\n",
    "end\n",
    "#=\n",
    "for i in 1:length(all_level)\n",
    "    load_all_OTU(all_level[i], \"non_augmented\")\n",
    "end\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5baa7bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#                         Load combinations                            #\n",
    "########################################################################\n",
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"]\n",
    "# soil+disease\n",
    "load_soil_disease()\n",
    "# alpha + soil\n",
    "for i in 1:length(all_level)\n",
    "    load_alpha_soil(all_level[i])\n",
    "    load_alpha_soil_disease(all_level[i])\n",
    "    load_otu_soil_disease(all_level[i])\n",
    "    load_otu_other(\"soil_chemistry_data\", all_level[i])\n",
    "    load_otu_other(\"disease_suppression_data\", all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6f2d5",
   "metadata": {},
   "source": [
    "# Testing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6407c51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CSV.read(\"../processed-data/all_otu_augmented/Family/1_1_test.csv\", DataFrame)\n",
    "#c = CSV.read(\"../processed-data/disease_suppression_data/original/1.csv\", DataFrame)\n",
    "#b = CSV.read(\"../processed-data/otu_soil_disease/Genus/full-data/6_1.csv\", DataFrame)\n",
    "\n",
    "size(a)[2]-1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
