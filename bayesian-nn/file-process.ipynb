{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c212b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using XLSX\n",
    "using Statistics\n",
    "using Glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe83b9b",
   "metadata": {},
   "source": [
    "# Generic Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f2aa536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_response (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_response(aug)\n",
    "    response_path = \"../processed-data/response/$aug/\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    return response\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdc9cb49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_generic_data (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_generic_data(data, level)\n",
    "    if level != \"null\"\n",
    "        path = \"../processed-data/$data/original/$level\"\n",
    "    else\n",
    "        path = \"../processed-data/$data/original\"\n",
    "    end\n",
    "    files = glob(\"*.csv\", path);\n",
    "    data = DataFrame.(CSV.File.(files))\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c2a5f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drop_miss (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function drop_miss(file) \n",
    "    file = file[completecases(file), :]\n",
    "    file = file[:, Not(1)]\n",
    "    rename!(file,:Link_ID => :Column1)\n",
    "    return file\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "608eed03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "select_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function select_otu(otu, res, res_idx, level, feature_sel, score)\n",
    "    if res_idx == 1\n",
    "        selected_feature = filter(row -> !(row.B != score), feature_sel)\n",
    "    elseif res_idx == 2\n",
    "        selected_feature = filter(row -> !(row.C != score), feature_sel)\n",
    "    elseif res_idx  == 3\n",
    "        selected_feature = filter(row -> !(row.D != score), feature_sel)\n",
    "    elseif res_idx == 4\n",
    "        selected_feature = filter(row -> !(row.E != score), feature_sel)\n",
    "    elseif res_idx == 5\n",
    "        selected_feature = filter(row -> !(row.F != score), feature_sel)\n",
    "    else\n",
    "        selected_feature = filter(row -> !(row.G != score), feature_sel)\n",
    "    end\n",
    "   \n",
    "    if score == 0 \n",
    "        if res_idx == 1\n",
    "            three_score = filter(row -> !(row.B != 3), feature_sel)\n",
    "        elseif res_idx == 2\n",
    "            three_score = filter(row -> !(row.C != 3), feature_sel)\n",
    "        elseif res_idx  == 3\n",
    "            three_score = filter(row -> !(row.D != 3), feature_sel)\n",
    "        elseif res_idx == 4\n",
    "            three_score = filter(row -> !(row.E != 3), feature_sel)\n",
    "        elseif res_idx == 5\n",
    "            three_score = filter(row -> !(row.F != 3), feature_sel)\n",
    "        else\n",
    "            three_score = filter(row -> !(row.G != 3), feature_sel)\n",
    "        end\n",
    "        three_num = size(three_score)[1]\n",
    "        if three_num <= size(selected_feature)[1]\n",
    "            feature_name = selected_feature[1:three_num, 1]\n",
    "        else\n",
    "            feature_name = selected_feature[:, 1]\n",
    "        end\n",
    "    else\n",
    "        feature_name = selected_feature[:, 1]\n",
    "    end\n",
    "    \n",
    "    \n",
    "    ###################################################################################\n",
    "    # WARNING: VERY WERID FEATURE NAME CHANGE, WILL REMOVE AFTER ADDRESSING THE ISSUE #\n",
    "    ###################################################################################\n",
    "    for i in 1:length(feature_name)\n",
    "        if feature_name[i][1] == 'X' && (Int(feature_name[i][2]) in 46:57)\n",
    "            feature_name[i] = replace(feature_name[i], \"X\" => \"\")\n",
    "        end\n",
    "    end\n",
    "    ####################################################################################\n",
    "    \n",
    "    id = otu[:, 1]\n",
    "    otu = otu[:, feature_name]\n",
    "    otu = convert.(Float64, otu)\n",
    "    otu = normalize(otu)\n",
    "    otu = hcat(id, otu)\n",
    "    rename!(otu,:x1 => :Column1)\n",
    "    return otu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "338246b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalize (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function normalize(otu) \n",
    "    for i in 1:size(otu)[1]\n",
    "        row_sum = sum(otu[i,:])\n",
    "        for j in 1:size(otu)[2]\n",
    "            convert(Float64, otu[i, j])\n",
    "            if row_sum == 0\n",
    "                otu[i,j] = 0\n",
    "            else\n",
    "                otu[i,j] = otu[i,j] / row_sum\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return otu\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b39506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "restruct_data (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function restruct_data(level)\n",
    "    data = CSV.read(\"../raw-data/Y1_F_$level.csv\", DataFrame)\n",
    "    data = data[data[:,2] .!= \"NA\", :]\n",
    "    nrow = size(data)[1]\n",
    "    ###################################################################################\n",
    "    # WARNING: VERY WERID FEATURE NAME CHANGE, WILL REMOVE AFTER ADDRESSING THE ISSUE #\n",
    "    ###################################################################################\n",
    "    for i in 1:nrow\n",
    "        data[i,2] = replace(data[i,2], \"-\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \" \" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"(\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \")\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"/\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"[\" => \".\")\n",
    "        data[i,2] = replace(data[i,2], \"]\" => \".\")\n",
    "    end\n",
    "    ####################################################################################\n",
    "    ncol = size(data)[2]\n",
    "    df = data[:, 3:ncol]\n",
    "    colnames = names(df)\n",
    "    df[!, :id] = data[:,2]\n",
    "    df1 = stack(df, colnames)\n",
    "    df_new = unstack(df1, :variable, :id, :value)\n",
    "    data = rename!(df_new, :variable => :Column1)\n",
    "    data = data[completecases(data), :]\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c103fc8",
   "metadata": {},
   "source": [
    "# All OTU Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f43810d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_raw_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_raw_otu(level)\n",
    "    otu = restruct_data(level)\n",
    "    response = load_response(\"non_augmented\")\n",
    "    for j in 1:length(response)\n",
    "        process_raw_otu(otu, response[j], j, level)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37293709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_raw_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_raw_otu(otu, res, res_idx, level)\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(1, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/all_otu_original/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9c23ec",
   "metadata": {},
   "source": [
    "# selected OTU\n",
    "Read all raw OTU counts -> restruct it -> select features by Rosa's selection table -> normalize by row sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0974fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process(otu, res, res_idx, level, feature_sel, score)\n",
    "    otu = select_otu(otu, res, res_idx, level, feature_sel, score)\n",
    "\n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(1, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/otu_selection/$score/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "094cf439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_otu(level, score)\n",
    "    # load important feature table\n",
    "    feature_selection = DataFrame(XLSX.readtable(\"../processed-data/otu_selection/important_features_score.xlsx\"\n",
    "            , \"$level\", \"A:G\", header=false))\n",
    "    \n",
    "    # load raw OTU count data\n",
    "    otu = restruct_data(level)\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "  \n",
    "    for j in 1:length(response)\n",
    "        process(otu, response[j], j, level, feature_selection, score)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db834ef",
   "metadata": {},
   "source": [
    "# All OTU -> augmented & non-augmented\n",
    "load all filtered normalizaed OTU by Rosa -> join with response -> save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c959c337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_all_OTU (generic function with 1 method)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_all_OTU(level, aug)\n",
    "    if aug == \"augmented\"\n",
    "        otu_path = \"../processed-data/all_otu_augmented/original/$level\"\n",
    "    else\n",
    "        otu_path = \"../processed-data/all_otu_non_augmented/original/$level\"\n",
    "    end\n",
    "    \n",
    "    otu_files = glob(\"*.csv\", otu_path)\n",
    "    otu = DataFrame.(CSV.File.(otu_files))\n",
    "\n",
    "    response = load_response(aug)\n",
    "\n",
    "    for i in 1:length(otu)\n",
    "        for j in 1:length(response)\n",
    "            process_all_otu(otu[i], response[j], i, j, level, aug)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc64087d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_all_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_all_otu(otu, res, otu_idx, res_idx, level, aug)\n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(otu_idx, \"_\", res_idx)\n",
    "    if aug == \"augmented\"\n",
    "        CSV.write(\"../processed-data/all_otu_augmented/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    else\n",
    "        CSV.write(\"../processed-data/all_otu_non_augmented/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f9f5e0",
   "metadata": {},
   "source": [
    "# All alpha diversity indices\n",
    "load all 5 levels of alpha diversity indices with 7 scaling methods -> join with response -> write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfb11b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha_process (generic function with 1 method)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function alpha_process(alpha, res, alpha_idx, res_idx, level)\n",
    "    alpha = drop_miss(alpha)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(alpha, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(alpha_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_index_data/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80798b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha(level)\n",
    "    alpha = load_generic_data(\"alpha_index_data\", level)\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(alpha)\n",
    "        for j in 1:length(response)\n",
    "            alpha_process(alpha[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f469560c",
   "metadata": {},
   "source": [
    "# Soil Chemistry & disease suppression\n",
    "load soil chemistry and disease suppression with 6 scaling methods -> join with responses -> write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb6b6c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_process (generic function with 1 method)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function other_process(file, res, pred_idx, res_idx, pred)\n",
    "    file = drop_miss(file)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(file, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/$pred/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b881f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_other (generic function with 1 method)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_other(pred)\n",
    "    data = load_generic_data(pred, \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            other_process(data[i], response[j], i, j, pred)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e888b1",
   "metadata": {},
   "source": [
    "# Soil Chemistry + Disease Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "637440a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_soil_disease()\n",
    "    data1 = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    data2 = load_generic_data(\"disease_suppression_data\", \"null\")\n",
    "    \n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data1)\n",
    "        for j in 1:length(response)\n",
    "            process_soil_disease(data1[i], data2[i], response[j], i, j)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5679dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_soil_disease(file1, file2, res, pred_idx, res_idx)\n",
    "    file1 = drop_miss(file1)\n",
    "    file2 = drop_miss(file2)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(file1, file2, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/soil_disease/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490da7db",
   "metadata": {},
   "source": [
    "# Alpha Diversity Indices + Soil Chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8bcecc22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha_soil (generic function with 1 method)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha_soil(level)\n",
    "    alpha = load_generic_data(\"alpha_index_data\", level);\n",
    "    data = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            process_alpha_soil(alpha[i],data[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bab2cdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_alpha_soil (generic function with 1 method)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_alpha_soil(alpha, file, res, pred_idx, res_idx, level)\n",
    "    alpha = drop_miss(alpha)\n",
    "    file = drop_miss(file)\n",
    "    \n",
    "    data = innerjoin(alpha, file, res, on = :Column1)\n",
    "    data = data[:, Not(1)]\n",
    "   \n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_soil/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d760621",
   "metadata": {},
   "source": [
    "# Alpha Diversity Indices + Soil Chemistry + Disease Suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "374c26af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha_soil_disease(level)\n",
    "    alpha = load_generic_data(\"alpha_index_data\", level);\n",
    "    data1 = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    data2 = load_generic_data(\"disease_suppression_data\", \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data1)\n",
    "        for j in 1:length(response)\n",
    "            process_alpha_soil_disease(alpha[i],data1[i], data2[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a881cde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process_alpha_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function process_alpha_soil_disease(alpha, file1, file2, res, pred_idx, res_idx, level)\n",
    "    alpha = drop_miss(alpha)\n",
    "    file1 = drop_miss(file1)\n",
    "    file2 = drop_miss(file2)\n",
    "    \n",
    "    data = innerjoin(alpha, file1, file2, res, on = :Column1)\n",
    "    data = data[:, Not(1)]\n",
    "   \n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_soil_disease/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0420ce4e",
   "metadata": {},
   "source": [
    "# OTU-Score=3 + Soil & OTU-Score=3 + disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd70be72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu_other (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_otu_other(data_name, level)\n",
    "    # load important feature table\n",
    "    feature_selection = DataFrame(XLSX.readtable(\"../processed-data/otu_selection/important_features_score.xlsx\"\n",
    "            , \"$level\", \"A:G\", header=false))\n",
    "    \n",
    "    # load raw OTU count data\n",
    "    otu = restruct_data(level)\n",
    "    data = load_generic_data(data_name, \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            otu_other_process(otu, data[i], response[j], i, j, level, feature_selection, data_name)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "853f43e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "otu_other_process (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function otu_other_process(otu, file, res, pred_idx, res_idx, level, feature_sel, dataName)\n",
    "    otu = select_otu(otu, res, res_idx, level, feature_sel, 3)\n",
    "    file = drop_miss(file)\n",
    "    \n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, file, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    if dataName == \"soil_chemistry_data\"\n",
    "        CSV.write(\"../processed-data/otu_soil/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    else\n",
    "        CSV.write(\"../processed-data/otu_disease/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edccdd3",
   "metadata": {},
   "source": [
    "# OTU-Score=3 + Soil + Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03af3cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu_soil_disease (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_otu_soil_disease(level)\n",
    "    # load important feature table\n",
    "    feature_selection = DataFrame(XLSX.readtable(\"../processed-data/otu_selection/important_features_score.xlsx\"\n",
    "            , \"$level\", \"A:G\", header=false))\n",
    "    \n",
    "    # load raw OTU count data\n",
    "    otu = restruct_data(level)\n",
    "    data1 = load_generic_data(\"soil_chemistry_data\", \"null\")\n",
    "    data2 = load_generic_data(\"disease_suppression_data\", \"null\")\n",
    "    \n",
    "    # load all responses\n",
    "    response = load_response(\"non_augmented\")\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data1)\n",
    "        for j in 1:length(response)\n",
    "            combined_process(otu, data1[i], data2[i], response[j], i, j, level, feature_selection)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bcde6171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "combined_process (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function combined_process(otu, file1, file2, res, pred_idx, res_idx, level, feature_sel)\n",
    "    otu = select_otu(otu, res, res_idx, level, feature_sel, 3)\n",
    "    file1 = drop_miss(file1)\n",
    "    file2 = drop_miss(file2)\n",
    "    \n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, file1, file2, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/otu_soil_disease/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5057addd",
   "metadata": {},
   "source": [
    "# All loading function calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "39eeff80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#                         Load OTU selection                           #\n",
    "########################################################################\n",
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"]\n",
    "\n",
    "# get all files for OTUs\n",
    "for i in 1:length(all_level)\n",
    "    for j in 0:3\n",
    "        load_otu(all_level[i], j)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "082111c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#                            Load Raw OTU                              #\n",
    "########################################################################\n",
    "for i in 1:length(all_level)\n",
    "    load_raw_otu(all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5096cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#                      Load Alpha Diversity Indices                    #\n",
    "########################################################################\n",
    "for i in 1:length(all_level)\n",
    "    load_alpha(all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c4aa49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#             Load Soil chemistry and disease suppression              #\n",
    "########################################################################\n",
    "load_other(\"soil_chemistry_data\")\n",
    "load_other(\"disease_suppression_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "22ee3256",
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#           Load Full OTU for both augmented and non_augmented         #\n",
    "########################################################################\n",
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\"]\n",
    "# get all files for OTUs\n",
    "for i in 1:length(all_level)\n",
    "    load_all_OTU(all_level[i], \"augmented\")\n",
    "end\n",
    "for i in 1:length(all_level)\n",
    "    load_all_OTU(all_level[i], \"non_augmented\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5baa7bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 58 for key MN_10_1_Y1 and variable Unknown.Family.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n",
      "┌ Warning: Duplicate entries in unstack at row 1162 for key MN_10_1_Y1 and variable Incertae.Sedis.\n",
      "└ @ DataFrames C:\\Users\\Administrator\\.julia\\packages\\DataFrames\\GtZ1l\\src\\abstractdataframe\\reshape.jl:208\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#                         Load combinations                            #\n",
    "########################################################################\n",
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"]\n",
    "# soil+disease\n",
    "load_soil_disease()\n",
    "# alpha + soil\n",
    "for i in 1:length(all_level)\n",
    "    load_alpha_soil(all_level[i])\n",
    "    load_alpha_soil_disease(all_level[i])\n",
    "    load_otu_soil_disease(all_level[i])\n",
    "    load_otu_other(\"soil_chemistry_data\", all_level[i])\n",
    "    load_otu_other(\"disease_suppression_data\", all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb6f2d5",
   "metadata": {},
   "source": [
    "# Testing Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "086b3cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>1.6555130696436529</th><th>1.2767062729003655</th><th>-0.312897861001188</th><th>1.4658221622536836</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>217 rows × 26 columns (omitted printing of 22 columns)</p><tr><th>1</th><td>1.29956</td><td>0.89299</td><td>-0.447952</td><td>0.861064</td></tr><tr><th>2</th><td>1.12158</td><td>1.16959</td><td>0.580159</td><td>1.22444</td></tr><tr><th>3</th><td>1.65551</td><td>1.5223</td><td>0.35197</td><td>1.68707</td></tr><tr><th>4</th><td>2.23394</td><td>2.10833</td><td>0.600586</td><td>2.16645</td></tr><tr><th>5</th><td>1.65551</td><td>1.2943</td><td>-0.283853</td><td>1.53046</td></tr><tr><th>6</th><td>1.52203</td><td>1.45022</td><td>0.460657</td><td>1.60082</td></tr><tr><th>7</th><td>1.789</td><td>1.47292</td><td>-0.137318</td><td>1.77061</td></tr><tr><th>8</th><td>2.10046</td><td>2.4893</td><td>1.75649</td><td>2.60345</td></tr><tr><th>9</th><td>1.16607</td><td>0.879405</td><td>-0.250564</td><td>0.992321</td></tr><tr><th>10</th><td>0.721129</td><td>1.0285</td><td>1.34547</td><td>0.810666</td></tr><tr><th>11</th><td>1.61102</td><td>1.81034</td><td>1.36819</td><td>1.56237</td></tr><tr><th>12</th><td>2.27844</td><td>2.29825</td><td>0.950334</td><td>2.44423</td></tr><tr><th>13</th><td>2.63439</td><td>2.60687</td><td>0.95006</td><td>2.77022</td></tr><tr><th>14</th><td>2.10046</td><td>1.72384</td><td>-0.0959421</td><td>1.91694</td></tr><tr><th>15</th><td>2.50091</td><td>2.591</td><td>1.44994</td><td>2.29872</td></tr><tr><th>16</th><td>1.38855</td><td>1.17155</td><td>0.164578</td><td>1.11108</td></tr><tr><th>17</th><td>2.14495</td><td>2.02178</td><td>0.449995</td><td>2.41286</td></tr><tr><th>18</th><td>1.16607</td><td>1.20486</td><td>0.58016</td><td>1.27385</td></tr><tr><th>19</th><td>-2.08202</td><td>-2.06719</td><td>-1.28828</td><td>-2.03684</td></tr><tr><th>20</th><td>0.00921798</td><td>-0.0629316</td><td>-0.23136</td><td>0.000418759</td></tr><tr><th>21</th><td>1.07709</td><td>0.808863</td><td>-0.250566</td><td>0.874095</td></tr><tr><th>22</th><td>0.721129</td><td>0.642485</td><td>0.16456</td><td>0.557518</td></tr><tr><th>23</th><td>-0.524716</td><td>-0.486181</td><td>-0.231377</td><td>-0.288494</td></tr><tr><th>24</th><td>-1.19213</td><td>-1.38755</td><td>-1.31726</td><td>-1.42519</td></tr><tr><th>25</th><td>-1.68157</td><td>-1.85088</td><td>-1.74615</td><td>-1.83994</td></tr><tr><th>26</th><td>-0.96966</td><td>-0.794997</td><td>0.219349</td><td>-0.915071</td></tr><tr><th>27</th><td>-1.01415</td><td>-1.12302</td><td>-0.912405</td><td>-1.07536</td></tr><tr><th>28</th><td>1.92248</td><td>1.94731</td><td>1.00226</td><td>1.82228</td></tr><tr><th>29</th><td>1.56652</td><td>1.3267</td><td>0.0903327</td><td>1.44974</td></tr><tr><th>30</th><td>1.92248</td><td>1.68857</td><td>0.321076</td><td>1.66411</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& 1.6555130696436529 & 1.2767062729003655 & -0.312897861001188 & 1.4658221622536836 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1.29956 & 0.89299 & -0.447952 & 0.861064 & $\\dots$ \\\\\n",
       "\t2 & 1.12158 & 1.16959 & 0.580159 & 1.22444 & $\\dots$ \\\\\n",
       "\t3 & 1.65551 & 1.5223 & 0.35197 & 1.68707 & $\\dots$ \\\\\n",
       "\t4 & 2.23394 & 2.10833 & 0.600586 & 2.16645 & $\\dots$ \\\\\n",
       "\t5 & 1.65551 & 1.2943 & -0.283853 & 1.53046 & $\\dots$ \\\\\n",
       "\t6 & 1.52203 & 1.45022 & 0.460657 & 1.60082 & $\\dots$ \\\\\n",
       "\t7 & 1.789 & 1.47292 & -0.137318 & 1.77061 & $\\dots$ \\\\\n",
       "\t8 & 2.10046 & 2.4893 & 1.75649 & 2.60345 & $\\dots$ \\\\\n",
       "\t9 & 1.16607 & 0.879405 & -0.250564 & 0.992321 & $\\dots$ \\\\\n",
       "\t10 & 0.721129 & 1.0285 & 1.34547 & 0.810666 & $\\dots$ \\\\\n",
       "\t11 & 1.61102 & 1.81034 & 1.36819 & 1.56237 & $\\dots$ \\\\\n",
       "\t12 & 2.27844 & 2.29825 & 0.950334 & 2.44423 & $\\dots$ \\\\\n",
       "\t13 & 2.63439 & 2.60687 & 0.95006 & 2.77022 & $\\dots$ \\\\\n",
       "\t14 & 2.10046 & 1.72384 & -0.0959421 & 1.91694 & $\\dots$ \\\\\n",
       "\t15 & 2.50091 & 2.591 & 1.44994 & 2.29872 & $\\dots$ \\\\\n",
       "\t16 & 1.38855 & 1.17155 & 0.164578 & 1.11108 & $\\dots$ \\\\\n",
       "\t17 & 2.14495 & 2.02178 & 0.449995 & 2.41286 & $\\dots$ \\\\\n",
       "\t18 & 1.16607 & 1.20486 & 0.58016 & 1.27385 & $\\dots$ \\\\\n",
       "\t19 & -2.08202 & -2.06719 & -1.28828 & -2.03684 & $\\dots$ \\\\\n",
       "\t20 & 0.00921798 & -0.0629316 & -0.23136 & 0.000418759 & $\\dots$ \\\\\n",
       "\t21 & 1.07709 & 0.808863 & -0.250566 & 0.874095 & $\\dots$ \\\\\n",
       "\t22 & 0.721129 & 0.642485 & 0.16456 & 0.557518 & $\\dots$ \\\\\n",
       "\t23 & -0.524716 & -0.486181 & -0.231377 & -0.288494 & $\\dots$ \\\\\n",
       "\t24 & -1.19213 & -1.38755 & -1.31726 & -1.42519 & $\\dots$ \\\\\n",
       "\t25 & -1.68157 & -1.85088 & -1.74615 & -1.83994 & $\\dots$ \\\\\n",
       "\t26 & -0.96966 & -0.794997 & 0.219349 & -0.915071 & $\\dots$ \\\\\n",
       "\t27 & -1.01415 & -1.12302 & -0.912405 & -1.07536 & $\\dots$ \\\\\n",
       "\t28 & 1.92248 & 1.94731 & 1.00226 & 1.82228 & $\\dots$ \\\\\n",
       "\t29 & 1.56652 & 1.3267 & 0.0903327 & 1.44974 & $\\dots$ \\\\\n",
       "\t30 & 1.92248 & 1.68857 & 0.321076 & 1.66411 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "217×26 DataFrame. Omitted printing of 23 columns\n",
       "│ Row │ 1.6555130696436529 │ 1.2767062729003655 │ -0.312897861001188 │\n",
       "│     │ \u001b[90mFloat64\u001b[39m            │ \u001b[90mFloat64\u001b[39m            │ \u001b[90mFloat64\u001b[39m            │\n",
       "├─────┼────────────────────┼────────────────────┼────────────────────┤\n",
       "│ 1   │ 1.29956            │ 0.89299            │ -0.447952          │\n",
       "│ 2   │ 1.12158            │ 1.16959            │ 0.580159           │\n",
       "│ 3   │ 1.65551            │ 1.5223             │ 0.35197            │\n",
       "│ 4   │ 2.23394            │ 2.10833            │ 0.600586           │\n",
       "│ 5   │ 1.65551            │ 1.2943             │ -0.283853          │\n",
       "│ 6   │ 1.52203            │ 1.45022            │ 0.460657           │\n",
       "│ 7   │ 1.789              │ 1.47292            │ -0.137318          │\n",
       "│ 8   │ 2.10046            │ 2.4893             │ 1.75649            │\n",
       "│ 9   │ 1.16607            │ 0.879405           │ -0.250564          │\n",
       "│ 10  │ 0.721129           │ 1.0285             │ 1.34547            │\n",
       "⋮\n",
       "│ 207 │ -1.28112           │ -1.27586           │ -0.571482          │\n",
       "│ 208 │ -0.836177          │ -0.964297          │ -0.906542          │\n",
       "│ 209 │ -1.4591            │ -1.19356           │ 0.324153           │\n",
       "│ 210 │ -1.50359           │ -1.54627           │ -1.04333           │\n",
       "│ 211 │ -0.747188          │ -0.655677          │ -0.00891833        │\n",
       "│ 212 │ -2.03753           │ -2.14587           │ -1.72618           │\n",
       "│ 213 │ -0.213254          │ -0.486066          │ -0.974901          │\n",
       "│ 214 │ 0.0537124          │ 0.00150104         │ -0.120193          │\n",
       "│ 215 │ 0.0537124          │ -0.2188            │ -0.863362          │\n",
       "│ 216 │ 0.187196           │ 0.298839           │ 0.457715           │\n",
       "│ 217 │ -0.0352765         │ -0.100162          │ -0.151279          │"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = CSV.read(\"../processed-data/alpha_soil_disease/Order/full-data/1_1.csv\", DataFrame)\n",
    "#c = CSV.read(\"../processed-data/disease_suppression_data/original/1.csv\", DataFrame)\n",
    "#b = CSV.read(\"../processed-data/otu_soil_disease/Genus/full-data/6_1.csv\", DataFrame)\n",
    "\n",
    "#names(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
