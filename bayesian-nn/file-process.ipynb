{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c212b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using XLSX\n",
    "using Statistics\n",
    "using Glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0974fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "process (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=\n",
    "This function removes the unnecessary columns for the input of BNN\n",
    "This function also writes the processed data into its respective CSV file\n",
    "=#\n",
    "function process(otu, res, otu_idx, res_idx, level, dis_feature, yie_feature, score)\n",
    "    \n",
    "    if res_idx == 1\n",
    "        selected_feature = filter(row -> !(row.B != score), dis_feature)\n",
    "    elseif res_idx == 2\n",
    "        selected_feature = filter(row -> !(row.C != score), dis_feature)\n",
    "    elseif res_idx  == 3\n",
    "        selected_feature = filter(row -> !(row.D != score), dis_feature)\n",
    "    elseif res_idx == 4\n",
    "        selected_feature = filter(row -> !(row.E != score), yie_feature)\n",
    "    elseif res_idx == 5\n",
    "        selected_feature = filter(row -> !(row.B != score), yie_feature)\n",
    "    else\n",
    "        selected_feature = filter(row -> !(row.F != score), yie_feature)\n",
    "    end\n",
    "    if score == 0 \n",
    "        if res_idx == 1\n",
    "            three_score = filter(row -> !(row.B != 3), dis_feature)\n",
    "        elseif res_idx == 2\n",
    "            three_score = filter(row -> !(row.C != 3), dis_feature)\n",
    "        elseif res_idx  == 3\n",
    "            three_score = filter(row -> !(row.D != 3), dis_feature)\n",
    "        elseif res_idx == 4\n",
    "            three_score = filter(row -> !(row.E != 3), yie_feature)\n",
    "        elseif res_idx == 5\n",
    "            three_score = filter(row -> !(row.B != 3), yie_feature)\n",
    "        else\n",
    "            three_score = filter(row -> !(row.F != 3), yie_feature)\n",
    "        end\n",
    "        three_num = size(three_score)[1]\n",
    "        if three_num <= size(selected_feature)[1]\n",
    "            feature_name = selected_feature[1:three_num, 1]\n",
    "        else\n",
    "            feature_name = selected_feature[:, 1]\n",
    "        end\n",
    "    else\n",
    "        feature_name = selected_feature[:, 1]\n",
    "    end\n",
    "    id = otu[:, 1]\n",
    "    otu = otu[:, feature_name]\n",
    "    otu = hcat(id, otu)\n",
    "    rename!(otu,:x1 => :Column1)\n",
    "    \n",
    "    \n",
    "    # join the otus and responses by sample ID\n",
    "    data = innerjoin(otu, res, on = :Column1)\n",
    "\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(otu_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/otu_data/non_augumented/$score/$level/full-data/$filename.csv\", Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "094cf439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_otu (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#= \n",
    "This function load the filtered otu and responses \n",
    "=#\n",
    "function load_otu(level, score)\n",
    "    # load important feature table\n",
    "    dis_feature = DataFrame(XLSX.readtable(\"../processed-data/disease_response_important_features.xlsx\"\n",
    "            , \"$level\", \"A:D\", header=false))\n",
    "    yie_feature = DataFrame(XLSX.readtable(\"../processed-data/yield_response_important_features.xlsx\"\n",
    "            , \"$level\", \"A:F\", header=false))\n",
    "    \n",
    "    # load all filtered data in one level folder\n",
    "    otu_path = \"../processed-data/otu_data/original/$level\"\n",
    "    otu_files = glob(\"*.csv\", otu_path);\n",
    "    otu = DataFrame.(CSV.File.(otu_files));\n",
    "    \n",
    "    # load all responses\n",
    "    response_path = \"../processed-data/response\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    \n",
    "    # pass them to process and write to new CSVs\n",
    "    for i in 1:length(otu)\n",
    "        for j in 1:length(response)\n",
    "            process(otu[i], response[j], i, j, level, dis_feature, yie_feature, score)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9dfb11b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha_process (generic function with 1 method)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function alpha_process(alpha, res, alpha_idx, res_idx, level)\n",
    "    alpha = alpha[:, Not(1)]\n",
    "    rename!(alpha,:Link_ID => :Column1)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(alpha, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1:2)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(alpha_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/alpha_index_data/non_augumented/$level/full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "80798b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_alpha (generic function with 1 method)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_alpha(level)\n",
    "    alpha_path = \"../processed-data/alpha_index_data/original/$level\"\n",
    "    alpha_files = glob(\"*.csv\", alpha_path);\n",
    "    alpha = DataFrame.(CSV.File.(alpha_files));\n",
    "    \n",
    "    # load all responses\n",
    "    response_path = \"../processed-data/response\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(alpha)\n",
    "        for j in 1:length(response)\n",
    "            alpha_process(alpha[i], response[j], i, j, level)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bb6b6c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other_process (generic function with 1 method)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function other_process(file, res, pred_idx, res_idx, pred)\n",
    "    file = file[completecases(file), :]\n",
    "    file = file[:, Not(1)]\n",
    "    rename!(file,:Link_ID => :Column1)\n",
    "    \n",
    "    # join the alphas and responses by sample ID\n",
    "    data = innerjoin(file, res, on = :Column1)\n",
    "    # remove the sample ID\n",
    "    data = data[:, Not(1:2)]\n",
    "    # write the data to a CSV file with its specified name\n",
    "    mat = Matrix(data)\n",
    "    filename = string(pred_idx, \"_\", res_idx)\n",
    "    CSV.write(\"../processed-data/$pred/non_augumented//full-data/$filename.csv\",\n",
    "        Tables.table(mat), header=false)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7b881f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_other (generic function with 1 method)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function load_other(pred)\n",
    "    path = \"../processed-data/$pred/original\"\n",
    "    files = glob(\"*.csv\", path);\n",
    "    data = DataFrame.(CSV.File.(files));\n",
    "    \n",
    "    # load all responses\n",
    "    response_path = \"../processed-data/response\"\n",
    "    response_files = glob(\"*.csv\", response_path)\n",
    "    response = DataFrame.(CSV.File.(response_files));\n",
    "    \n",
    "     # pass them to process and write to new CSVs\n",
    "    for i in 1:length(data)\n",
    "        for j in 1:length(response)\n",
    "            other_process(data[i], response[j], i, j, pred)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39eeff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_level = [\"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"]\n",
    "\n",
    "# get all files for OTUs\n",
    "for i in 1:length(all_level)\n",
    "    for j in 0:3\n",
    "        load_otu(all_level[i], j)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5096cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all files for alpha diversity index\n",
    "for i in 1:length(all_level)\n",
    "    load_alpha(all_level[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4aa49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_other(\"soil_chemistry_data\")\n",
    "load_other(\"disease_suppression_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "65b23328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>0.20243566481418684</th><th>-0.05166937418938376</th><th>2.0805408871782096</th><th>1.0</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th></tr></thead><tbody><p>229 rows × 4 columns</p><tr><th>1</th><td>-0.133313</td><td>-0.276311</td><td>2.20249</td><td>1.0</td></tr><tr><th>2</th><td>0.31251</td><td>0.0744208</td><td>2.09905</td><td>1.0</td></tr><tr><th>3</th><td>-0.0680612</td><td>-0.469369</td><td>2.03198</td><td>1.0</td></tr><tr><th>4</th><td>-0.119547</td><td>0.322787</td><td>1.89412</td><td>1.0</td></tr><tr><th>5</th><td>-0.1481</td><td>0.105263</td><td>2.00765</td><td>1.0</td></tr><tr><th>6</th><td>0.802748</td><td>0.412761</td><td>2.3174</td><td>1.0</td></tr><tr><th>7</th><td>0.0841525</td><td>-0.0724293</td><td>2.59411</td><td>1.0</td></tr><tr><th>8</th><td>0.82726</td><td>0.0228143</td><td>2.29037</td><td>1.0</td></tr><tr><th>9</th><td>0.396765</td><td>0.0054676</td><td>1.92636</td><td>1.0</td></tr><tr><th>10</th><td>0.459371</td><td>0.133622</td><td>1.91127</td><td>1.0</td></tr><tr><th>11</th><td>0.028008</td><td>-0.4228</td><td>2.29243</td><td>1.0</td></tr><tr><th>12</th><td>-0.716248</td><td>-0.0664085</td><td>1.04779</td><td>0.0</td></tr><tr><th>13</th><td>0.191996</td><td>-0.746064</td><td>1.65208</td><td>1.0</td></tr><tr><th>14</th><td>-0.943163</td><td>-0.462238</td><td>1.50285</td><td>1.0</td></tr><tr><th>15</th><td>-1.02329</td><td>-0.188794</td><td>1.63274</td><td>1.0</td></tr><tr><th>16</th><td>-0.527271</td><td>-0.411525</td><td>1.45812</td><td>1.0</td></tr><tr><th>17</th><td>-0.519566</td><td>0.153756</td><td>1.80664</td><td>1.0</td></tr><tr><th>18</th><td>0.34893</td><td>-0.262358</td><td>1.25712</td><td>1.0</td></tr><tr><th>19</th><td>-0.121053</td><td>-1.35128</td><td>1.01773</td><td>1.0</td></tr><tr><th>20</th><td>0.028506</td><td>-1.50431</td><td>0.501194</td><td>1.0</td></tr><tr><th>21</th><td>1.00936</td><td>-0.598117</td><td>1.41037</td><td>1.0</td></tr><tr><th>22</th><td>0.865498</td><td>-0.0994291</td><td>1.4994</td><td>1.0</td></tr><tr><th>23</th><td>-0.0963243</td><td>-1.289</td><td>0.562235</td><td>1.0</td></tr><tr><th>24</th><td>2.05074</td><td>-0.0899774</td><td>-0.482</td><td>1.0</td></tr><tr><th>25</th><td>3.33731</td><td>0.259369</td><td>-0.300289</td><td>1.0</td></tr><tr><th>26</th><td>2.5837</td><td>1.0258</td><td>-0.0505127</td><td>1.0</td></tr><tr><th>27</th><td>0.882707</td><td>0.633026</td><td>-0.381464</td><td>1.0</td></tr><tr><th>28</th><td>0.75008</td><td>-0.535918</td><td>-0.967364</td><td>1.0</td></tr><tr><th>29</th><td>0.346486</td><td>0.517934</td><td>-0.300702</td><td>1.0</td></tr><tr><th>30</th><td>0.724591</td><td>-0.626831</td><td>1.73362</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& 0.20243566481418684 & -0.05166937418938376 & 2.0805408871782096 & 1.0\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64\\\\\n",
       "\t\\hline\n",
       "\t1 & -0.133313 & -0.276311 & 2.20249 & 1.0 \\\\\n",
       "\t2 & 0.31251 & 0.0744208 & 2.09905 & 1.0 \\\\\n",
       "\t3 & -0.0680612 & -0.469369 & 2.03198 & 1.0 \\\\\n",
       "\t4 & -0.119547 & 0.322787 & 1.89412 & 1.0 \\\\\n",
       "\t5 & -0.1481 & 0.105263 & 2.00765 & 1.0 \\\\\n",
       "\t6 & 0.802748 & 0.412761 & 2.3174 & 1.0 \\\\\n",
       "\t7 & 0.0841525 & -0.0724293 & 2.59411 & 1.0 \\\\\n",
       "\t8 & 0.82726 & 0.0228143 & 2.29037 & 1.0 \\\\\n",
       "\t9 & 0.396765 & 0.0054676 & 1.92636 & 1.0 \\\\\n",
       "\t10 & 0.459371 & 0.133622 & 1.91127 & 1.0 \\\\\n",
       "\t11 & 0.028008 & -0.4228 & 2.29243 & 1.0 \\\\\n",
       "\t12 & -0.716248 & -0.0664085 & 1.04779 & 0.0 \\\\\n",
       "\t13 & 0.191996 & -0.746064 & 1.65208 & 1.0 \\\\\n",
       "\t14 & -0.943163 & -0.462238 & 1.50285 & 1.0 \\\\\n",
       "\t15 & -1.02329 & -0.188794 & 1.63274 & 1.0 \\\\\n",
       "\t16 & -0.527271 & -0.411525 & 1.45812 & 1.0 \\\\\n",
       "\t17 & -0.519566 & 0.153756 & 1.80664 & 1.0 \\\\\n",
       "\t18 & 0.34893 & -0.262358 & 1.25712 & 1.0 \\\\\n",
       "\t19 & -0.121053 & -1.35128 & 1.01773 & 1.0 \\\\\n",
       "\t20 & 0.028506 & -1.50431 & 0.501194 & 1.0 \\\\\n",
       "\t21 & 1.00936 & -0.598117 & 1.41037 & 1.0 \\\\\n",
       "\t22 & 0.865498 & -0.0994291 & 1.4994 & 1.0 \\\\\n",
       "\t23 & -0.0963243 & -1.289 & 0.562235 & 1.0 \\\\\n",
       "\t24 & 2.05074 & -0.0899774 & -0.482 & 1.0 \\\\\n",
       "\t25 & 3.33731 & 0.259369 & -0.300289 & 1.0 \\\\\n",
       "\t26 & 2.5837 & 1.0258 & -0.0505127 & 1.0 \\\\\n",
       "\t27 & 0.882707 & 0.633026 & -0.381464 & 1.0 \\\\\n",
       "\t28 & 0.75008 & -0.535918 & -0.967364 & 1.0 \\\\\n",
       "\t29 & 0.346486 & 0.517934 & -0.300702 & 1.0 \\\\\n",
       "\t30 & 0.724591 & -0.626831 & 1.73362 & 1.0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "229×4 DataFrame. Omitted printing of 1 columns\n",
       "│ Row │ 0.20243566481418684 │ -0.05166937418938376 │ 2.0805408871782096 │\n",
       "│     │ \u001b[90mFloat64\u001b[39m             │ \u001b[90mFloat64\u001b[39m              │ \u001b[90mFloat64\u001b[39m            │\n",
       "├─────┼─────────────────────┼──────────────────────┼────────────────────┤\n",
       "│ 1   │ -0.133313           │ -0.276311            │ 2.20249            │\n",
       "│ 2   │ 0.31251             │ 0.0744208            │ 2.09905            │\n",
       "│ 3   │ -0.0680612          │ -0.469369            │ 2.03198            │\n",
       "│ 4   │ -0.119547           │ 0.322787             │ 1.89412            │\n",
       "│ 5   │ -0.1481             │ 0.105263             │ 2.00765            │\n",
       "│ 6   │ 0.802748            │ 0.412761             │ 2.3174             │\n",
       "│ 7   │ 0.0841525           │ -0.0724293           │ 2.59411            │\n",
       "│ 8   │ 0.82726             │ 0.0228143            │ 2.29037            │\n",
       "│ 9   │ 0.396765            │ 0.0054676            │ 1.92636            │\n",
       "│ 10  │ 0.459371            │ 0.133622             │ 1.91127            │\n",
       "⋮\n",
       "│ 219 │ -0.363793           │ -1.10526             │ -0.225505          │\n",
       "│ 220 │ 0.343144            │ -1.51965             │ -0.54719           │\n",
       "│ 221 │ -3.10688            │ -2.13793             │ -0.738114          │\n",
       "│ 222 │ -0.208216           │ 0.89107              │ -0.448714          │\n",
       "│ 223 │ 0.383753            │ -0.570644            │ -0.900161          │\n",
       "│ 224 │ -0.427115           │ 0.107117             │ -0.745181          │\n",
       "│ 225 │ 0.441837            │ 0.671628             │ -0.374341          │\n",
       "│ 226 │ -0.793512           │ 0.247176             │ -0.985877          │\n",
       "│ 227 │ -1.51546            │ 0.270093             │ -0.61671           │\n",
       "│ 228 │ -1.00276            │ 0.647279             │ -0.86579           │\n",
       "│ 229 │ -1.33174            │ -1.5367              │ -1.48051           │"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a = CSV.read(\"../processed-data/disease_suppression_data/non_augumented/full-data/1_1.csv\", DataFrame, header=true)\n",
    "\n",
    "#a[completecases(a), :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
