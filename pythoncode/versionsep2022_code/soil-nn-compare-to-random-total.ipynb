{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "500c1bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(['bmh'])\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import  classification_report\n",
    "from sklearn.model_selection import RepeatedKFold,train_test_split\n",
    "import os\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6eb53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe3e19",
   "metadata": {},
   "source": [
    "# Comparing to random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "194a42a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Compare_random(data,data_train,data_val,cv,NumofR):\n",
    "#     x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "#     pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "#     param_grid = [\n",
    "#     {'classifier' : [RandomForestClassifier()],\n",
    "#     'classifier__criterion':('gini','entropy'),\n",
    "#     'classifier__class_weight':('balanced','auto')}]\n",
    "#     clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "#     clf.fit(data_train[x_column_list],data_train['y_b'])\n",
    "#     best_clf=clf.best_estimator_\n",
    "#     y_valid=best_clf.predict(data_val[x_column_list])\n",
    "    \n",
    "#     report_RF = classification_report(data_val['y_b'],y_valid,output_dict=True) \n",
    "    \n",
    "#     F1_0_class_RF=report_RF['0.0']['f1-score']\n",
    "#     F1_1_class_RF=report_RF['1.0']['f1-score']\n",
    "    \n",
    "#     pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "#     param_grid = [\n",
    "#     {'classifier' : [RandomForestClassifier()],\n",
    "#     'classifier__criterion':('gini','entropy'),\n",
    "#     'classifier__class_weight':('balanced','auto')}]\n",
    "#     totalF1_0=[]\n",
    "#     totalF1_1=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         RD1= np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1])\n",
    "#         RD1=pd.DataFrame(RD1)\n",
    "#         RD1.columns =data[x_column_list].columns\n",
    "#         RD11=RD1.div(RD1.sum(axis=1), axis=0)        \n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(RD11.iloc[0:data_train.shape[0],0:len(x_column_list)], data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(RD11.iloc[data_train.shape[0]:,0:len(x_column_list)])\n",
    "#         report_Random1 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0.append(report_Random1 ['0.0']['f1-score'])\n",
    "#         totalF1_1.append(report_Random1 ['1.0']['f1-score'])    \n",
    "#     r1=pd.DataFrame()\n",
    "#     r1['0']= totalF1_0\n",
    "#     r1['1']= totalF1_1\n",
    "#     EV1=r1[(r1['0'] >= F1_0_class_RF) & (r1['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #senario2\n",
    "#     totalF1_0_2=[]\n",
    "#     totalF1_1_2=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         RD2=pd.DataFrame(np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1]))\n",
    "#         RD2.columns=data[x_column_list].columns\n",
    "#         for col in data[x_column_list].columns:\n",
    "#             dd=np.where(data[x_column_list][col]==0)[0]\n",
    "#             if len(dd)>0:\n",
    "#                 RD2[col][dd]=0\n",
    "#         RD22=RD2.div(RD2.sum(axis=1), axis=0)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(RD22[x_column_list][0:data_train.shape[0]], data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(RD22[x_column_list][data_train.shape[0]:])\n",
    "#         report_Random2 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_2.append(report_Random2['0.0']['f1-score'])\n",
    "#         totalF1_1_2.append(report_Random2['1.0']['f1-score'])\n",
    "#     r2=pd.DataFrame()\n",
    "#     r2['0']= totalF1_0_2\n",
    "#     r2['1']= totalF1_1_2\n",
    "#     EV2=r2[(r2['0'] >= F1_0_class_RF) & (r2['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #senario3\n",
    "#     totalF1_0_3=[]\n",
    "#     totalF1_1_3=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         YR=np.random.permutation(data['y_b'].values)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(data_train[x_column_list],  YR[0:data_train[x_column_list].shape[0]])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(data_val[x_column_list])\n",
    "#         report_Random3 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_3.append(report_Random3['0.0']['f1-score'])\n",
    "#         totalF1_1_3.append(report_Random3['1.0']['f1-score'])\n",
    "#     r3=pd.DataFrame()\n",
    "#     r3['0']= totalF1_0_3\n",
    "#     r3['1']= totalF1_1_3\n",
    "#     EV3=r3[(r3['0'] >= F1_0_class_RF) & (r3['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     #Senario4\n",
    "#     totalF1_0_4=[]\n",
    "#     totalF1_1_4=[]\n",
    "#     for i in range(1,NumofR):\n",
    "#         DR=data[x_column_list].sample(frac=1)\n",
    "#         clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "#         clf.fit(DR[0:data_train[x_column_list].shape[0]],  data_train['y_b'])\n",
    "#         best_clf=clf.best_estimator_\n",
    "#         y_valid=best_clf.predict(DR[data_train[x_column_list].shape[0]:])\n",
    "#         report_Random4 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "#         totalF1_0_4.append(report_Random4['0.0']['f1-score'])\n",
    "#         totalF1_1_4.append(report_Random4['1.0']['f1-score'])\n",
    "#     r4=pd.DataFrame()\n",
    "#     r4['0']= totalF1_0_4\n",
    "#     r4['1']= totalF1_1_4\n",
    "#     EV4=r4[(r4['0'] >= F1_0_class_RF) & (r4['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "#     ev_value=[EV1,EV2,EV3,EV4]\n",
    "#     return r1,r2,r3,r4,ev_value,F1_0_class_RF,F1_1_class_RF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f43c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=RepeatedKFold(n_splits=10,n_repeats=3, random_state=100)\n",
    "th=0.05\n",
    "q=0.7\n",
    "NumofR=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f294b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yield_per_plant\n",
      " 1 _ 1 .csv\n",
      "[0.5, 0.38, 0.42, 0.43]\n",
      "no_tuber_scabpit\n",
      " 1 _ 1 .csv\n",
      "[0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "path_response='/Users/rosa/Desktop/ALLWork/Madison/Project/Soil-nn/Code/python code local/Main Data Files/randomization/'  \n",
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r') & (file_response[0] != 'O'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID','x1':'y_b'}, inplace=True)  \n",
    "                response.drop(columns=response.columns[2], inplace=True)  \n",
    "                response=response.drop(columns='Variety2')  \n",
    "                path_x = '/Users/rosa/Desktop/ALLWork/Madison/Project/Soil-nn/Code/python code local/Main Data Files/OTUData-1-1/'  \n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF'+'.xlsx', engine='xlsxwriter')   \n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()  \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file)  \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True)  \n",
    "                                data=pd.merge(response,data_temp,on='Link_ID')  \n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)\n",
    "                                out_random = Compare_random(data,data_train,data_val,cv,NumofR)\n",
    "                                #output_dic[file] = [out_random[0],out_random[1], out_random[2],out_random[3],out_random[4],out_random[5],out_random[6]]\n",
    "                                fig, axs = plt.subplots(1,4, figsize=(20, 10), facecolor='w', edgecolor='k')\n",
    "                                fig.subplots_adjust(hspace =0.1, wspace=0.2)\n",
    "\n",
    "                                plt.subplot(1,4,1)\n",
    "                                r1=out_random[0]\n",
    "                                plt.scatter(r1['0'],r1['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 1')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.subplot(1,4,2)\n",
    "                                r2=out_random[1]\n",
    "                                plt.scatter(r2['0'],r2['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 2')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.subplot(1,4,3)\n",
    "                                r3=out_random[2]\n",
    "                                plt.scatter(r3['0'],r3['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0---Strategy 3')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.subplot(1,4,4)\n",
    "                                r4=out_random[3]\n",
    "                                plt.scatter(r4['0'],r4['1'])\n",
    "                                plt.scatter(out_random[5],out_random[6])\n",
    "                                plt.xlabel('F1-score label 0--Strategy 4')\n",
    "                                plt.ylabel('F1-score label 1')\n",
    "                                plt.savefig(path_response+file_response+'/'+file_folder+'.png',facecolor='white')\n",
    "                                plt.close()\n",
    "                                print(out_random[4])    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f46e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc4fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67e9269a",
   "metadata": {},
   "source": [
    "# Version2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef2384e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Compare_random(data,data_train,data_val,cv,NumofR):\n",
    "    x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "    pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])\n",
    "    param_grid = [\n",
    "    {'classifier' : [RandomForestClassifier()],\n",
    "    'classifier__criterion':('gini','entropy'),\n",
    "    'classifier__class_weight':('balanced','auto')}]\n",
    "    clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "\n",
    "    clf.fit(data_train[x_column_list],data_train['y_b'])\n",
    "    best_clf=clf.best_estimator_\n",
    "    y_valid=best_clf.predict(data_val[x_column_list])\n",
    "\n",
    "    report_RF = classification_report(data_val['y_b'],y_valid,output_dict=True) \n",
    "\n",
    "    F1_0_class_RF=report_RF['0.0']['f1-score']\n",
    "    F1_1_class_RF=report_RF['1.0']['f1-score']\n",
    "\n",
    "    totalF1_0=[]\n",
    "    totalF1_1=[]\n",
    "    for i in range(1,NumofR):\n",
    "        RD1= np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1])\n",
    "        RD1=pd.DataFrame(RD1)\n",
    "        RD1.columns =data[x_column_list].columns\n",
    "        RD11=RD1.div(RD1.sum(axis=1), axis=0)        \n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(RD11.iloc[data_train.index,0:len(x_column_list)], data_train['y_b'])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(RD11.iloc[data_val.index,0:len(x_column_list)])\n",
    "        report_Random1 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0.append(report_Random1 ['0.0']['f1-score'])\n",
    "        totalF1_1.append(report_Random1 ['1.0']['f1-score'])    \n",
    "    r1=pd.DataFrame()\n",
    "    r1['0']= totalF1_0\n",
    "    r1['1']= totalF1_1\n",
    "    EV1=r1[(r1['0'] >= F1_0_class_RF) & (r1['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "    #senario2\n",
    "    totalF1_0_2=[]\n",
    "    totalF1_1_2=[]\n",
    "    for i in range(1,NumofR):\n",
    "        RD2=pd.DataFrame(np.random.rand(data[x_column_list].shape[0],data[x_column_list].shape[1]))\n",
    "        RD2.columns=data[x_column_list].columns\n",
    "        for col in data[x_column_list].columns:\n",
    "            dd=np.where(data[x_column_list][col]==0)[0]\n",
    "            if len(dd)>0:\n",
    "                RD2[col][dd]=0\n",
    "        RD22=RD2.div(RD2.sum(axis=1), axis=0)\n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(RD22.iloc[data_train.index][x_column_list], data_train['y_b'])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(RD22.iloc[data_val.index][x_column_list])\n",
    "        report_Random2 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0_2.append(report_Random2['0.0']['f1-score'])\n",
    "        totalF1_1_2.append(report_Random2['1.0']['f1-score'])\n",
    "    r2=pd.DataFrame()\n",
    "    r2['0']= totalF1_0_2\n",
    "    r2['1']= totalF1_1_2\n",
    "    EV2=r2[(r2['0'] >= F1_0_class_RF) & (r2['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "    #senario3\n",
    "    totalF1_0_3=[]\n",
    "    totalF1_1_3=[]\n",
    "    for i in range(1,NumofR):\n",
    "        YR=np.random.permutation(data['y_b'].values)\n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(data_train[x_column_list],  YR[0:data_train[x_column_list].shape[0]])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(data_val[x_column_list])\n",
    "        report_Random3 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0_3.append(report_Random3['0.0']['f1-score'])\n",
    "        totalF1_1_3.append(report_Random3['1.0']['f1-score'])\n",
    "    r3=pd.DataFrame()\n",
    "    r3['0']= totalF1_0_3\n",
    "    r3['1']= totalF1_1_3\n",
    "    EV3=r3[(r3['0'] >= F1_0_class_RF) & (r3['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "    #Senario4\n",
    "    totalF1_0_4=[]\n",
    "    totalF1_1_4=[]\n",
    "    for i in range(1,NumofR):\n",
    "        DR=data[x_column_list].sample(frac=1)\n",
    "        clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')\n",
    "        clf.fit(DR[0:data_train[x_column_list].shape[0]],  data_train['y_b'])\n",
    "        best_clf=clf.best_estimator_\n",
    "        y_valid=best_clf.predict(DR[data_train[x_column_list].shape[0]:])\n",
    "        report_Random4 = classification_report(data_val['y_b'],y_valid,output_dict=True)\n",
    "        totalF1_0_4.append(report_Random4['0.0']['f1-score'])\n",
    "        totalF1_1_4.append(report_Random4['1.0']['f1-score'])\n",
    "    r4=pd.DataFrame()\n",
    "    r4['0']= totalF1_0_4\n",
    "    r4['1']= totalF1_1_4\n",
    "    EV4=r4[(r4['0'] >= F1_0_class_RF) & (r4['1'] >=F1_1_class_RF)].shape[0]/ NumofR\n",
    "    ev_value=[EV1,EV2,EV3,EV4]\n",
    "\n",
    "\n",
    "    return r1,r2,r3,r4,ev_value,F1_0_class_RF,F1_1_class_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1654b360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906fc91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598fde47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2228cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b5460d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ad2634",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
