{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69988add",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import ExcelWriter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import openpyxl\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "421a931f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7fbaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "012db601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "start_time = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60133f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_level = ['Class', 'Family', 'Genus', 'Order', 'Phylum']\n",
    "path_local='/Users/rosa/Desktop/ALLWork/Madison/Project/Soil-nn/Code/python code local/Git_RF/'\n",
    "path_response=path_local+'response/response_original/' \n",
    "data_path = path_local+'response/response_netcomi/'\n",
    "path_Count=path_local+'OTU/Count_data/'\n",
    "path_soil = path_local+'Env/soil_chemistry/'\n",
    "path_disease = path_local+'Env/disease_suppression/'\n",
    "path_field=path_local+'Env/field_information/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab79a226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_train,data_val,cv):  \n",
    "    x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "    percent_label=[round(100*len(np.where(data_train['y_b']==0)[0])/len(data_train)),round(100*len(np.where(data_val['y_b']==0)[0])/len(data_val))]  \n",
    "    #Classification RF  \n",
    "    pipeRF = Pipeline([('classifier', [RandomForestClassifier()])])  \n",
    "    param_grid = [  \n",
    "    {'classifier' : [RandomForestClassifier()], \n",
    "    'classifier__n_estimators': [100, 200],\n",
    "    'classifier__min_samples_split': [8, 10],\n",
    "    'classifier__min_samples_leaf': [3, 4, 5],\n",
    "     'classifier__max_depth': [80, 90],\n",
    "    'classifier__criterion':('gini','entropy'),  \n",
    "    'classifier__class_weight':('balanced','auto')}]  \n",
    "    clf = GridSearchCV(pipeRF, param_grid = param_grid, cv = cv, n_jobs=-1, scoring='f1_weighted')  \n",
    "    # Fit on data  \n",
    "    clf.fit(data_train[x_column_list],data_train['y_b'])  \n",
    "    best_clf=clf.best_estimator_  \n",
    "    y_valid=best_clf.predict(data_val[x_column_list])  \n",
    "    report_All = classification_report(data_val['y_b'],y_valid,output_dict=True)  \n",
    "    dAll=pd.DataFrame(report_All).transpose()  \n",
    "    return dAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc9ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=RepeatedKFold(n_splits=10,n_repeats=3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f53ab77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 6)\n",
      "(85, 6)\n",
      "(162, 6)\n",
      "(36, 6)\n",
      "(30, 6)\n"
     ]
    }
   ],
   "source": [
    "path_list2 = []\n",
    "#reading files in folder response\n",
    "for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "    for path in dirs:\n",
    "        path_list2.append(path)\n",
    "#reading sheet name       \n",
    "wb = openpyxl.load_workbook(path_response+path+'/feature_selection.xlsx')\n",
    "sheet_list = wb.sheetnames\n",
    "\n",
    "results_dic = dict.fromkeys(sheet_list)\n",
    "\n",
    "for sheet_name in results_dic.keys():\n",
    "    temp_df = pd.DataFrame(columns=path_list2, index=range(0,700))\n",
    "    for folder in path_list2:\n",
    "        data_temp = pd.read_excel(path_response+folder+'/feature_selection.xlsx', sheet_name=sheet_name)\n",
    "        temp_df[folder].iloc[\n",
    "            range(0, len(data_temp['Unnamed: 0'].values))] = data_temp['Unnamed: 0'].values\n",
    "    if sheet_name =='Phylum':\n",
    "        temp_df = temp_df.iloc[range(0,30)]\n",
    "    elif sheet_name =='Class':\n",
    "        temp_df = temp_df.iloc[range(0,36)]\n",
    "    elif sheet_name =='Order':\n",
    "        temp_df = temp_df.iloc[range(0,75)]\n",
    "    elif sheet_name =='Family':\n",
    "        temp_df = temp_df.iloc[range(0,85)]\n",
    "    elif sheet_name =='Genus':\n",
    "        temp_df = temp_df.iloc[range(0,162)]\n",
    "        \n",
    "    results_dic[sheet_name] = temp_df\n",
    "    print( results_dic[sheet_name].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a75b9824",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(data_path, topdown=False):\n",
    "    for path in dirs:\n",
    "        path_list.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "477ac4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 9)\n",
      "(75, 9)\n",
      "(30, 9)\n",
      "(85, 9)\n",
      "(162, 9)\n",
      "(36, 9)\n",
      "(75, 9)\n",
      "(30, 9)\n",
      "(85, 9)\n",
      "(162, 9)\n",
      "(36, 9)\n",
      "(75, 9)\n",
      "(30, 9)\n",
      "(85, 9)\n",
      "(162, 9)\n",
      "(36, 9)\n",
      "(75, 9)\n",
      "(30, 9)\n",
      "(85, 9)\n",
      "(162, 9)\n",
      "(36, 9)\n",
      "(75, 9)\n",
      "(30, 9)\n",
      "(85, 9)\n",
      "(162, 9)\n",
      "(36, 9)\n",
      "(75, 9)\n",
      "(30, 9)\n",
      "(85, 9)\n",
      "(162, 9)\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "all_data = dict.fromkeys(dirs)\n",
    "for folder in path_list:\n",
    "    \n",
    "    all_data[folder] = dict.fromkeys(list_level)\n",
    "    temp_path = data_path+folder\n",
    "    temp_file_list = os.listdir(temp_path)\n",
    "    for file in temp_file_list:\n",
    "        if 'Count' in file:\n",
    "            level = file.split('_')[-1][:-4]\n",
    "            data_temp = pd.read_csv(data_path+folder+'/'+file,index_col=0)\n",
    "            data_temp.sort_values(by='abs.diff..x', ascending=False, inplace=True)\n",
    "            all_data[folder][level] = data_temp.iloc[range(0,max(30, round(len(data_temp)/3)))]\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6236f413",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "(36,)\n",
      "(36,)\n",
      "106\n",
      "29\n",
      "23\n",
      "23\n",
      "21\n",
      "26\n",
      "28\n",
      "Family\n",
      "(85,)\n",
      "(85,)\n",
      "248\n",
      "57\n",
      "58\n",
      "63\n",
      "62\n",
      "55\n",
      "69\n",
      "Genus\n",
      "(162,)\n",
      "(162,)\n",
      "477\n",
      "117\n",
      "117\n",
      "108\n",
      "134\n",
      "109\n",
      "118\n",
      "Order\n",
      "(75,)\n",
      "(75,)\n",
      "219\n",
      "49\n",
      "54\n",
      "56\n",
      "58\n",
      "52\n",
      "59\n",
      "Phylum\n",
      "(30,)\n",
      "(30,)\n",
      "42\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "10\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    print(all_data[response][level].index.shape)\n",
    "    print(results_dic[level][response].shape)\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi\n",
    "   \n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==2].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)\n",
    "    #matrix_df.to_excel(writer, sheet_name=level, index=True)\n",
    "writer.save()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "726a0441",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m data_train,data_val \u001b[38;5;241m=\u001b[39m train_test_split(data,train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[0;32m---> 38\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     39\u001b[0m tRF[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues) \n\u001b[1;32m     40\u001b[0m tRF2[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame([file_response,file_folder, np\u001b[38;5;241m.\u001b[39masarray(A)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m4\u001b[39m]])\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_train, data_val, cv)\u001b[0m\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeRF, param_grid \u001b[38;5;241m=\u001b[39m param_grid, cv \u001b[38;5;241m=\u001b[39m cv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     17\u001b[0m best_clf\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_estimator_  \n\u001b[1;32m     18\u001b[0m y_valid\u001b[38;5;241m=\u001b[39mbest_clf\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                path_x = path_Count  \n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF_FS_Netcomi'+'.xlsx', engine='xlsxwriter')   \n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()\n",
    "                        k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file) \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                A = [item for item in SELECTED_FEATURE[file_folder][file_response]]\n",
    "                                A.insert(0, \"Link_ID\")\n",
    "                                data_temp = data_temp[A]\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True)  \n",
    "                                RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                data_temp = pd.concat([data_temp['Link_ID'],RD11],axis=1)                            \n",
    "                                data=pd.merge(response,data_temp,on='Link_ID')\n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data.dropna(inplace=True)\n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)  \n",
    "                                output = process_data(data_train,data_val,cv)  \n",
    "                                tRF[k]=pd.DataFrame(output['f1-score'].values) \n",
    "                                k=k+1           \n",
    "                        tRF.to_excel(writer, sheet_name=file_folder, index=True) \n",
    "                writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad5d74a",
   "metadata": {},
   "source": [
    "# ML result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f2d02519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "106\n",
      "29\n",
      "23\n",
      "23\n",
      "21\n",
      "26\n",
      "28\n",
      "Family\n",
      "248\n",
      "57\n",
      "58\n",
      "63\n",
      "62\n",
      "55\n",
      "69\n",
      "Genus\n",
      "477\n",
      "117\n",
      "117\n",
      "108\n",
      "134\n",
      "109\n",
      "118\n",
      "Order\n",
      "219\n",
      "49\n",
      "54\n",
      "56\n",
      "58\n",
      "52\n",
      "59\n",
      "Phylum\n",
      "42\n",
      "9\n",
      "7\n",
      "9\n",
      "5\n",
      "9\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi\n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==1].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec339cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     42\u001b[0m data_train,data_val \u001b[38;5;241m=\u001b[39m train_test_split(data,train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[0;32m---> 43\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     44\u001b[0m tRF[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues) \n\u001b[1;32m     45\u001b[0m tRF2[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame([file_response,file_folder, np\u001b[38;5;241m.\u001b[39masarray(A)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m4\u001b[39m]])\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_train, data_val, cv)\u001b[0m\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeRF, param_grid \u001b[38;5;241m=\u001b[39m param_grid, cv \u001b[38;5;241m=\u001b[39m cv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     17\u001b[0m best_clf\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_estimator_  \n\u001b[1;32m     18\u001b[0m y_valid\u001b[38;5;241m=\u001b[39mbest_clf\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                path_x = path_Count  \n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF_FS_ML'+'.xlsx', engine='xlsxwriter')   \n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame() \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)                                  \n",
    "                                 \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file) \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                A = [item for item in SELECTED_FEATURE[file_folder][file_response]]\n",
    "                                A.insert(0, \"Link_ID\")\n",
    "                                data_temp = data_temp[A]\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True)  \n",
    "                                RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                data_temp = pd.concat([data_temp['Link_ID'],RD11],axis=1)\n",
    "                                \n",
    "                                data=pd.merge(response,data_temp,on='Link_ID')\n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data.dropna(inplace=True)\n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)  \n",
    "                                output = process_data(data_train,data_val,cv)  \n",
    "                                tRF[k]=pd.DataFrame(output['f1-score'].values) \n",
    "                                k=k+1           \n",
    "                        tRF.to_excel(writer, sheet_name=file_folder, index=True) \n",
    "                writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a93262",
   "metadata": {},
   "source": [
    "# important OTU (ML&Netcomi)Score==3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc2a28cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "106\n",
      "Family\n",
      "248\n",
      "Genus\n",
      "477\n",
      "Order\n",
      "219\n",
      "Phylum\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi\n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==3].index\n",
    "    \n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "18f031cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     36\u001b[0m data_train,data_val \u001b[38;5;241m=\u001b[39m train_test_split(data,train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[0;32m---> 37\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     38\u001b[0m tRF[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues) \n\u001b[1;32m     39\u001b[0m tRF2[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame([file_response,file_folder, np\u001b[38;5;241m.\u001b[39masarray(A)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m4\u001b[39m]])\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_train, data_val, cv)\u001b[0m\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeRF, param_grid \u001b[38;5;241m=\u001b[39m param_grid, cv \u001b[38;5;241m=\u001b[39m cv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     17\u001b[0m best_clf\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_estimator_  \n\u001b[1;32m     18\u001b[0m y_valid\u001b[38;5;241m=\u001b[39mbest_clf\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                path_x = path_Count\n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF_FS_score3'+'.xlsx', engine='xlsxwriter')   \n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()  \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file) \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                A = [item for item in SELECTED_FEATURE[file_folder][file_response]]\n",
    "                                A.insert(0, \"Link_ID\")\n",
    "                                data_temp = data_temp[A]\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True)  \n",
    "                                RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                data_temp = pd.concat([data_temp['Link_ID'],RD11],axis=1)        \n",
    "                                data=pd.merge(response,data_temp,on='Link_ID')\n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data.dropna(inplace=True)\n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)  \n",
    "                                output = process_data(data_train,data_val,cv)  \n",
    "                                tRF[k]=pd.DataFrame(output['f1-score'].values) \n",
    "                                k=k+1\n",
    "                                \n",
    "                        tRF.to_excel(writer, sheet_name=file_folder, index=True)  \n",
    "                writer.save()                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f27d534",
   "metadata": {},
   "source": [
    "# Not important (Score0) size=size _score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b001e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "106\n",
      "7\n",
      "13\n",
      "13\n",
      "15\n",
      "10\n",
      "8\n",
      "Family\n",
      "248\n",
      "28\n",
      "27\n",
      "22\n",
      "23\n",
      "30\n",
      "16\n",
      "Genus\n",
      "477\n",
      "45\n",
      "45\n",
      "54\n",
      "28\n",
      "53\n",
      "44\n",
      "Order\n",
      "219\n",
      "26\n",
      "21\n",
      "19\n",
      "17\n",
      "23\n",
      "16\n",
      "Phylum\n",
      "42\n",
      "21\n",
      "21\n",
      "21\n",
      "25\n",
      "20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "SELECTED_FEATURE_0 = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    SELECTED_FEATURE_0[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi   \n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==3].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "        SELECTED_FEATURE_0[level][response] = matrix_df[response][matrix_df[response]==0].index[0:SELECTED_FEATURE[level][response].shape[0]] \n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3cfb883c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m data\u001b[38;5;241m.\u001b[39mdropna(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     37\u001b[0m data_train,data_val \u001b[38;5;241m=\u001b[39m train_test_split(data,train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[0;32m---> 38\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     39\u001b[0m tRF[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues) \n\u001b[1;32m     40\u001b[0m tRF2[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame([file_response,file_folder, np\u001b[38;5;241m.\u001b[39masarray(A)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m4\u001b[39m]])\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_train, data_val, cv)\u001b[0m\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeRF, param_grid \u001b[38;5;241m=\u001b[39m param_grid, cv \u001b[38;5;241m=\u001b[39m cv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     17\u001b[0m best_clf\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_estimator_  \n\u001b[1;32m     18\u001b[0m y_valid\u001b[38;5;241m=\u001b[39mbest_clf\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)   \n",
    "                path_x = path_Count\n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF_FS_notImportant'+'.xlsx', engine='xlsxwriter')   \n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()  \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file) \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                A = [item for item in SELECTED_FEATURE_0[file_folder][file_response]]\n",
    "                                A.insert(0, \"Link_ID\")\n",
    "                                data_temp = data_temp[A]\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True)  \n",
    "                                RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                data_temp = pd.concat([data_temp['Link_ID'],RD11],axis=1)\n",
    "                                data=pd.merge(response,data_temp,on='Link_ID')\n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data.dropna(inplace=True)\n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)  \n",
    "                                output = process_data(data_train,data_val,cv)  \n",
    "                                tRF[k]=pd.DataFrame(output['f1-score'].values) \n",
    "                                k=k+1                \n",
    "                        tRF.to_excel(writer, sheet_name=file_folder, index=True)  \n",
    "                writer.save()                      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563cbbbb",
   "metadata": {},
   "source": [
    "# disease_suppression+important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "34bc7bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 6)\n",
      "(85, 6)\n",
      "(162, 6)\n",
      "(36, 6)\n",
      "(30, 6)\n"
     ]
    }
   ],
   "source": [
    "path_list2 = []\n",
    "#reading files in folder response\n",
    "for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "    for path in dirs:\n",
    "        path_list2.append(path)\n",
    "#reading sheet name       \n",
    "wb = openpyxl.load_workbook(path_response+path+'/feature_selection.xlsx')\n",
    "sheet_list = wb.sheetnames\n",
    "\n",
    "results_dic = dict.fromkeys(sheet_list)\n",
    "\n",
    "for sheet_name in results_dic.keys():\n",
    "    temp_df = pd.DataFrame(columns=path_list2, index=range(0,700))\n",
    "    for folder in path_list2:\n",
    "        data_temp = pd.read_excel(path_response+folder+'/feature_selection.xlsx', sheet_name=sheet_name)\n",
    "        temp_df[folder].iloc[\n",
    "            range(0, len(data_temp['Unnamed: 0'].values))] = data_temp['Unnamed: 0'].values\n",
    "    if sheet_name =='Phylum':\n",
    "        temp_df = temp_df.iloc[range(0,30)]\n",
    "    elif sheet_name =='Class':\n",
    "        temp_df = temp_df.iloc[range(0,36)]\n",
    "    elif sheet_name =='Order':\n",
    "        temp_df = temp_df.iloc[range(0,75)]\n",
    "    elif sheet_name =='Family':\n",
    "        temp_df = temp_df.iloc[range(0,85)]\n",
    "    elif sheet_name =='Genus':\n",
    "        temp_df = temp_df.iloc[range(0,162)]\n",
    "        \n",
    "    results_dic[sheet_name] = temp_df\n",
    "    print( results_dic[sheet_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bda3cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "(36,)\n",
      "(36,)\n",
      "106\n",
      "7\n",
      "13\n",
      "13\n",
      "15\n",
      "10\n",
      "8\n",
      "Family\n",
      "(85,)\n",
      "(85,)\n",
      "248\n",
      "28\n",
      "27\n",
      "22\n",
      "23\n",
      "30\n",
      "16\n",
      "Genus\n",
      "(162,)\n",
      "(162,)\n",
      "477\n",
      "45\n",
      "45\n",
      "54\n",
      "28\n",
      "53\n",
      "44\n",
      "Order\n",
      "(75,)\n",
      "(75,)\n",
      "219\n",
      "26\n",
      "21\n",
      "19\n",
      "17\n",
      "23\n",
      "16\n",
      "Phylum\n",
      "(30,)\n",
      "(30,)\n",
      "42\n",
      "21\n",
      "21\n",
      "21\n",
      "25\n",
      "20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs) \n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    print(all_data[response][level].index.shape)\n",
    "    print(results_dic[level][response].shape)\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi   \n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==3].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)\n",
    "    matrix_df.to_excel(writer, sheet_name=level, index=True)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "645c40de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLink_ID\u001b[39m\u001b[38;5;124m'\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[1;32m     46\u001b[0m data_train,data_val \u001b[38;5;241m=\u001b[39m train_test_split(data,train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[0;32m---> 47\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     48\u001b[0m tRF[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues) \n\u001b[1;32m     49\u001b[0m tRF2[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame([file_response,file_folder, np\u001b[38;5;241m.\u001b[39masarray(A)\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m4\u001b[39m]])\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_train, data_val, cv)\u001b[0m\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeRF, param_grid \u001b[38;5;241m=\u001b[39m param_grid, cv \u001b[38;5;241m=\u001b[39m cv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     17\u001b[0m best_clf\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_estimator_  \n\u001b[1;32m     18\u001b[0m y_valid\u001b[38;5;241m=\u001b[39mbest_clf\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                path_x = path_Count\n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF_FS_disease_suppression'+'.xlsx', engine='xlsxwriter')   \n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()   \n",
    "                        k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file) \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                A = [item for item in SELECTED_FEATURE[file_folder][file_response]]\n",
    "                                A.insert(0, \"Link_ID\")\n",
    "                                data_temp = data_temp[A]\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                data_temp_original = pd.concat([data_temp['Link_ID'],RD11],axis=1)\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                for k in range(1,7):\n",
    "                                    fe = pd.read_csv(path_disease+str(k)+'.csv')\n",
    "                                    fe = fe.drop('Unnamed: 0',axis=1)\n",
    "                                    data_temp = pd.merge(data_temp_original,fe,on='Link_ID')\n",
    "\n",
    "                                    data=pd.merge(response,data_temp,on='Link_ID')\n",
    "                                    data.dropna(inplace=True)\n",
    "                                \n",
    "                                data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)  \n",
    "                                output = process_data(data_train,data_val,cv)  \n",
    "                                tRF[k]=pd.DataFrame(output['f1-score'].values) \n",
    "                                k=k+1  \n",
    "                        tRF.to_excel(writer, sheet_name=file_folder, index=True) \n",
    "                writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccea0ac",
   "metadata": {},
   "source": [
    "# soil_chemistry+important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "255d70ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 6)\n",
      "(85, 6)\n",
      "(162, 6)\n",
      "(36, 6)\n",
      "(30, 6)\n"
     ]
    }
   ],
   "source": [
    "path_list2 = []\n",
    "#reading files in folder response\n",
    "for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "    for path in dirs:\n",
    "        path_list2.append(path)\n",
    "#reading sheet name       \n",
    "wb = openpyxl.load_workbook(path_response+path+'/feature_selection.xlsx')\n",
    "sheet_list = wb.sheetnames\n",
    "\n",
    "results_dic = dict.fromkeys(sheet_list)\n",
    "\n",
    "for sheet_name in results_dic.keys():\n",
    "    temp_df = pd.DataFrame(columns=path_list2, index=range(0,700))\n",
    "    for folder in path_list2:\n",
    "        data_temp = pd.read_excel(path_response+folder+'/feature_selection.xlsx', sheet_name=sheet_name)\n",
    "        temp_df[folder].iloc[\n",
    "            range(0, len(data_temp['Unnamed: 0'].values))] = data_temp['Unnamed: 0'].values\n",
    "    if sheet_name =='Phylum':\n",
    "        temp_df = temp_df.iloc[range(0,30)]\n",
    "    elif sheet_name =='Class':\n",
    "        temp_df = temp_df.iloc[range(0,36)]\n",
    "    elif sheet_name =='Order':\n",
    "        temp_df = temp_df.iloc[range(0,75)]\n",
    "    elif sheet_name =='Family':\n",
    "        temp_df = temp_df.iloc[range(0,85)]\n",
    "    elif sheet_name =='Genus':\n",
    "        temp_df = temp_df.iloc[range(0,162)]\n",
    "        \n",
    "    results_dic[sheet_name] = temp_df\n",
    "    print( results_dic[sheet_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ebf9e2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "(36,)\n",
      "(36,)\n",
      "106\n",
      "7\n",
      "13\n",
      "13\n",
      "15\n",
      "10\n",
      "8\n",
      "Family\n",
      "(85,)\n",
      "(85,)\n",
      "248\n",
      "28\n",
      "27\n",
      "22\n",
      "23\n",
      "30\n",
      "16\n",
      "Genus\n",
      "(162,)\n",
      "(162,)\n",
      "477\n",
      "45\n",
      "45\n",
      "54\n",
      "28\n",
      "53\n",
      "44\n",
      "Order\n",
      "(75,)\n",
      "(75,)\n",
      "219\n",
      "26\n",
      "21\n",
      "19\n",
      "17\n",
      "23\n",
      "16\n",
      "Phylum\n",
      "(30,)\n",
      "(30,)\n",
      "42\n",
      "21\n",
      "21\n",
      "21\n",
      "25\n",
      "20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    print(all_data[response][level].index.shape)\n",
    "    print(results_dic[level][response].shape)\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi \n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==3].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bab271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m data\u001b[38;5;241m.\u001b[39mdrop(columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLink_ID\u001b[39m\u001b[38;5;124m'\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n\u001b[1;32m     47\u001b[0m data_train,data_val \u001b[38;5;241m=\u001b[39m train_test_split(data,train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)  \n\u001b[0;32m---> 48\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     49\u001b[0m tRF[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame(output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues) \n\u001b[1;32m     50\u001b[0m tRF2[k]\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame([file_response,file_folder, data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],output[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m4\u001b[39m]])\n",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36mprocess_data\u001b[0;34m(data_train, data_val, cv)\u001b[0m\n\u001b[1;32m     14\u001b[0m clf \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeRF, param_grid \u001b[38;5;241m=\u001b[39m param_grid, cv \u001b[38;5;241m=\u001b[39m cv, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1_weighted\u001b[39m\u001b[38;5;124m'\u001b[39m)  \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     17\u001b[0m best_clf\u001b[38;5;241m=\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_estimator_  \n\u001b[1;32m     18\u001b[0m y_valid\u001b[38;5;241m=\u001b[39mbest_clf\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                path_x = path_Count\n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF_FS_soil_chemistry'+'.xlsx', engine='xlsxwriter')\n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame()  \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        #k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file) \n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                A = [item for item in SELECTED_FEATURE[file_folder][file_response]]\n",
    "                                A.insert(0, \"Link_ID\")\n",
    "                                data_temp = data_temp[A]\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                data_temp_original = pd.concat([data_temp['Link_ID'],RD11],axis=1)\n",
    "                                \n",
    "                                \n",
    "                                \n",
    "                                for k in range(1,7):\n",
    "                                    fe = pd.read_csv(path_soil+str(k)+'.csv')\n",
    "                                    fe = fe.drop('Unnamed: 0',axis=1)\n",
    "                                    data_temp = pd.merge(data_temp_original,fe,on='Link_ID')\n",
    "\n",
    "                                    data=pd.merge(response,data_temp,on='Link_ID')\n",
    "                                    data.dropna(inplace=True)\n",
    "\n",
    "                                    data.drop(columns = 'Link_ID',inplace=True)  \n",
    "                                    data_train,data_val = train_test_split(data,train_size=0.8, random_state=42)  \n",
    "                                    output = process_data(data_train,data_val,cv)  \n",
    "                                    tRF[k]=pd.DataFrame(output['f1-score'].values) \n",
    "                                    \n",
    "                        tRF.to_excel(writer, sheet_name=file_folder, index=True)  \n",
    "                writer.save() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa83189",
   "metadata": {},
   "source": [
    "# Field_information+important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5204808d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 6)\n",
      "(85, 6)\n",
      "(162, 6)\n",
      "(36, 6)\n",
      "(30, 6)\n"
     ]
    }
   ],
   "source": [
    "path_list2 = []\n",
    "#reading files in folder response\n",
    "for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "    for path in dirs:\n",
    "        path_list2.append(path)\n",
    "#reading sheet name       \n",
    "wb = openpyxl.load_workbook(path_response+path+'/feature_selection.xlsx')\n",
    "sheet_list = wb.sheetnames\n",
    "\n",
    "results_dic = dict.fromkeys(sheet_list)\n",
    "\n",
    "for sheet_name in results_dic.keys():\n",
    "    temp_df = pd.DataFrame(columns=path_list2, index=range(0,700))\n",
    "    for folder in path_list2:\n",
    "        data_temp = pd.read_excel(path_response+folder+'/feature_selection.xlsx', sheet_name=sheet_name)\n",
    "        temp_df[folder].iloc[\n",
    "            range(0, len(data_temp['Unnamed: 0'].values))] = data_temp['Unnamed: 0'].values\n",
    "    if sheet_name =='Phylum':\n",
    "        temp_df = temp_df.iloc[range(0,30)]\n",
    "    elif sheet_name =='Class':\n",
    "        temp_df = temp_df.iloc[range(0,36)]\n",
    "    elif sheet_name =='Order':\n",
    "        temp_df = temp_df.iloc[range(0,75)]\n",
    "    elif sheet_name =='Family':\n",
    "        temp_df = temp_df.iloc[range(0,85)]\n",
    "    elif sheet_name =='Genus':\n",
    "        temp_df = temp_df.iloc[range(0,162)]\n",
    "        \n",
    "    results_dic[sheet_name] = temp_df\n",
    "    print( results_dic[sheet_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dae812f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "(36,)\n",
      "(36,)\n",
      "106\n",
      "7\n",
      "13\n",
      "13\n",
      "15\n",
      "10\n",
      "8\n",
      "Family\n",
      "(85,)\n",
      "(85,)\n",
      "248\n",
      "28\n",
      "27\n",
      "22\n",
      "23\n",
      "30\n",
      "16\n",
      "Genus\n",
      "(162,)\n",
      "(162,)\n",
      "477\n",
      "45\n",
      "45\n",
      "54\n",
      "28\n",
      "53\n",
      "44\n",
      "Order\n",
      "(75,)\n",
      "(75,)\n",
      "219\n",
      "26\n",
      "21\n",
      "19\n",
      "17\n",
      "23\n",
      "16\n",
      "Phylum\n",
      "(30,)\n",
      "(30,)\n",
      "42\n",
      "21\n",
      "21\n",
      "21\n",
      "25\n",
      "20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    print(all_data[response][level].index.shape)\n",
    "    print(results_dic[level][response].shape)\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi   \n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==3].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "285820e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(\n",
    "min_samples_leaf=50,\n",
    "n_estimators=150,\n",
    "bootstrap=True,\n",
    "oob_score=True,\n",
    "n_jobs=-1,\n",
    "random_state=42,\n",
    "max_features='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7265a202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [48]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(col_trans, rf_classifier)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     69\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])\n\u001b[1;32m     71\u001b[0m report_All \u001b[38;5;241m=\u001b[39m classification_report(data_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_b\u001b[39m\u001b[38;5;124m'\u001b[39m],y_valid,output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:465\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_))\n\u001b[0;32m--> 465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:466\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarm_start \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# We draw from the random state to get the random state we\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;66;03m# would have got if we hadn't used a warm_start.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_))\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 466\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_estimator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mappend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/ensemble/_base.py:164\u001b[0m, in \u001b[0;36mBaseEnsemble._make_estimator\u001b[0;34m(self, append, random_state)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m\"\"\"Make and configure a copy of the `base_estimator_` attribute.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03mWarning: This method should be used to properly instantiate new\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;124;03msub-estimators.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    163\u001b[0m estimator \u001b[38;5;241m=\u001b[39m clone(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_estimator_)\n\u001b[0;32m--> 164\u001b[0m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator_params\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# TODO: Remove in v1.2\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;66;03m# criterion \"mse\" and \"mae\" would cause warnings in every call to\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;66;03m# DecisionTreeRegressor.fit(..)\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(estimator, (DecisionTreeRegressor, ExtraTreeRegressor)):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/base.py:239\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m params:\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# Simple optimization to gain speed (inspect is slow)\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 239\u001b[0m valid_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m nested_params \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mdict\u001b[39m)  \u001b[38;5;66;03m# grouped by prefix\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/base.py:212\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[1;32m    211\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget_params\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    213\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    214\u001b[0m         out\u001b[38;5;241m.\u001b[39mupdate((key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m k, val) \u001b[38;5;28;01mfor\u001b[39;00m k, val \u001b[38;5;129;01min\u001b[39;00m deep_items)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)  \n",
    "                path_x = path_Count\n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_RF_FS_field_information'+'.xlsx', engine='xlsxwriter')\n",
    "                for file_folder in os.listdir(path_x):  \n",
    "                    if (file_folder[-4:] != '.csv') & (file_folder != '.DS_Store')& (file_folder != 'Icon\\r'):          \n",
    "                        path = path_x+file_folder  \n",
    "                        os.chdir(path)  \n",
    "                        file_list = []  \n",
    "                        tRF=pd.DataFrame() \n",
    "                        tcluster=pd.DataFrame()  \n",
    "                        k=0  \n",
    "                        for file in os.listdir(path):  \n",
    "                            if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file_folder != 'Icon\\r'):  \n",
    "                                print(file)  \n",
    "                                file_list.append(file)  \n",
    "                                data_temp = pd.read_csv(file)\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                A = [item for item in SELECTED_FEATURE[file_folder][file_response]]\n",
    "                                A.insert(0, \"Link_ID\")\n",
    "                                data_temp = data_temp[A]\n",
    "                                data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                data_temp = pd.concat([data_temp['Link_ID'],RD11],axis=1)\n",
    "                                \n",
    "                                \n",
    "                                fe=pd.read_csv(path_field+'field_information.csv')\n",
    "                                fe.rename(columns={'Column1':'Link_ID'},inplace=True)\n",
    "                                A = fe.columns[fe.isna().sum()< 30]\n",
    "\n",
    "                                fe = fe[A]\n",
    "                                \n",
    "                                level_cols = fe.columns \n",
    "                                level_cols =level_cols.drop(['Link_ID','Variety'])\n",
    "                                \n",
    "                                features_to_encode = level_cols.drop(['pH_1_1'])\n",
    "                                \n",
    "                                col_trans = make_column_transformer(\n",
    "                                (OneHotEncoder(),features_to_encode),\n",
    "                                remainder = \"passthrough\")\n",
    "                                df_scaled = fe[level_cols]\n",
    "                                fe_data=pd.concat([fe['Link_ID'],df_scaled],axis=1)\n",
    "                                data_temp = pd.merge(data_temp,fe_data,on='Link_ID')\n",
    "                                \n",
    "                                data=pd.merge(response,data_temp,on='Link_ID')\n",
    "                                data.drop(columns = ['Link_ID','pH_1_1'],inplace=True)\n",
    "                                data.dropna(inplace=True)\n",
    "                                AL = []\n",
    "                                for l in range(0,50):\n",
    "                                    data_train,data_val = train_test_split(data,train_size=0.97, random_state=l)\n",
    "\n",
    "\n",
    "                                    x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "                                    #Classification RF \n",
    "\n",
    "                                    pipe = make_pipeline(col_trans, rf_classifier)\n",
    "                                    # Fit on data  \n",
    "                                    pipe.fit(data_train[x_column_list],data_train['y_b'])  \n",
    "                                    y_valid = pipe.predict(data_val[x_column_list])\n",
    "\n",
    "                                    report_All = classification_report(data_val['y_b'],y_valid,output_dict=True)  \n",
    "                                    dAll=pd.DataFrame(report_All).transpose() \n",
    "                                    AL.append(dAll['f1-score'].values)\n",
    "                                AAA=pd.DataFrame(AL)\n",
    "                                tRF[k]=AAA.mean()  \n",
    "\n",
    "                                k=k+1  \n",
    "                        tRF.to_excel(writer, sheet_name=file_folder, index=True) \n",
    "                        \n",
    "                writer.save()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0634db49",
   "metadata": {},
   "source": [
    "# important_otu+soil+disease+field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4642bb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe=pd.read_csv(path_field+'field_information.csv')\n",
    "fe.rename(columns={\"Column1\":'Link_ID'},inplace=True)\n",
    "A = fe.columns[fe.isna().sum()< 30]\n",
    "fe = fe[A]\n",
    "level_cols = fe.columns \n",
    "level_cols =level_cols.drop(['Link_ID','Variety'])\n",
    "features_to_encode = level_cols.drop(['pH_1_1'])\n",
    "col_trans = make_column_transformer((OneHotEncoder(),features_to_encode),remainder = \"passthrough\")\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "min_samples_leaf=50,\n",
    "n_estimators=150,\n",
    "bootstrap=True,\n",
    "oob_score=True,\n",
    "n_jobs=-1,\n",
    "random_state=42,\n",
    "max_features='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c99f695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 6)\n",
      "(85, 6)\n",
      "(162, 6)\n",
      "(36, 6)\n",
      "(30, 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path_list2 = []\n",
    "#reading files in folder response\n",
    "for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "    for path in dirs:\n",
    "        path_list2.append(path)\n",
    "#reading sheet name       \n",
    "wb = openpyxl.load_workbook(path_response+path+'/feature_selection.xlsx')\n",
    "sheet_list = wb.sheetnames\n",
    "\n",
    "results_dic = dict.fromkeys(sheet_list)\n",
    "\n",
    "for sheet_name in results_dic.keys():\n",
    "    temp_df = pd.DataFrame(columns=path_list2, index=range(0,700))\n",
    "    for folder in path_list2:\n",
    "        data_temp = pd.read_excel(path_response+folder+'/feature_selection.xlsx', sheet_name=sheet_name)\n",
    "        temp_df[folder].iloc[\n",
    "            range(0, len(data_temp['Unnamed: 0'].values))] = data_temp['Unnamed: 0'].values\n",
    "    if sheet_name =='Phylum':\n",
    "        temp_df = temp_df.iloc[range(0,30)]\n",
    "    elif sheet_name =='Class':\n",
    "        temp_df = temp_df.iloc[range(0,36)]\n",
    "    elif sheet_name =='Order':\n",
    "        temp_df = temp_df.iloc[range(0,75)]\n",
    "    elif sheet_name =='Family':\n",
    "        temp_df = temp_df.iloc[range(0,85)]\n",
    "    elif sheet_name =='Genus':\n",
    "        temp_df = temp_df.iloc[range(0,162)]\n",
    "        \n",
    "    results_dic[sheet_name] = temp_df\n",
    "    print( results_dic[sheet_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "920a459c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "(36,)\n",
      "(36,)\n",
      "106\n",
      "7\n",
      "13\n",
      "13\n",
      "15\n",
      "10\n",
      "8\n",
      "Family\n",
      "(85,)\n",
      "(85,)\n",
      "248\n",
      "28\n",
      "27\n",
      "22\n",
      "23\n",
      "30\n",
      "16\n",
      "Genus\n",
      "(162,)\n",
      "(162,)\n",
      "477\n",
      "45\n",
      "45\n",
      "54\n",
      "28\n",
      "53\n",
      "44\n",
      "Order\n",
      "(75,)\n",
      "(75,)\n",
      "219\n",
      "26\n",
      "21\n",
      "19\n",
      "17\n",
      "23\n",
      "16\n",
      "Phylum\n",
      "(30,)\n",
      "(30,)\n",
      "42\n",
      "21\n",
      "21\n",
      "21\n",
      "25\n",
      "20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    print(all_data[response][level].index.shape)\n",
    "    print(results_dic[level][response].shape)\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi\n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==3].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "627145a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yield_Plant\n",
      "(209, 23)\n",
      "CountOTUY1_F_Order.csv\n",
      "(209, 23)\n",
      "CountOTUY1_F_Order.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [52]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m pipe \u001b[38;5;241m=\u001b[39m make_pipeline(col_trans, rf_classifier)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Fit on data  \u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_column_list\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my_b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[1;32m     62\u001b[0m y_valid \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mpredict(data_val[x_column_list])\n\u001b[1;32m     64\u001b[0m report_All \u001b[38;5;241m=\u001b[39m classification_report(data_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_b\u001b[39m\u001b[38;5;124m'\u001b[39m],y_valid,output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/pipeline.py:382\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    381\u001b[0m         fit_params_last_step \u001b[38;5;241m=\u001b[39m fit_params_steps[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_last_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/multiprocessing/pool.py:762\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:600\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    598\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 600\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/soil_env2/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for file_response in os.listdir(path_response):  \n",
    "    if (file_response != '.DS_Store') & (file_response != 'Icon\\r'):  \n",
    "        print(file_response)  \n",
    "        path_r= path_response+file_response  \n",
    "        os.chdir(path_r)  \n",
    "        for re in os.listdir(path_r):  \n",
    "            if re[0:8] == 'response':  \n",
    "                response = pd.read_csv(path_response+file_response+'/'+re)  \n",
    "                response.rename(columns={'Column1':'Link_ID',response.columns[1]:'y_b'}, inplace=True)     \n",
    "                path_x = path_Count\n",
    "                writer= pd.ExcelWriter(path_r+'/'+'classification_important_otu+soil+disease+field'+'.xlsx', engine='xlsxwriter')\n",
    "    \n",
    "                tRF=pd.DataFrame()    \n",
    "                k=0  \n",
    "                for level in os.listdir(path_x):\n",
    "                    if (level[-4:] != '.csv') &  (level != '.DS_Store'):\n",
    "                        for k in range(1,7):\n",
    "                            #f1 = pd.read_csv(path_alpah+level+'/'+str(k)+'.csv')\n",
    "                            f2 = pd.read_csv(path_soil+str(k)+'.csv')\n",
    "                            #f12 = pd.merge(f1,f2,on='Link_ID')\n",
    "                            f3 = pd.read_csv(path_disease+str(k)+'.csv')\n",
    "                            f23=pd.merge(f2,f3,on='Link_ID')\n",
    "                            f23.drop(columns=['Unnamed: 0_x','Unnamed: 0_y'],inplace=True)\n",
    "                            data1 = pd.merge(response,f23,on='Link_ID')\n",
    "                            fe_data=pd.concat([fe['Link_ID'],fe[level_cols]],axis=1)\n",
    "                            \n",
    "                            data = pd.merge(data1,fe_data,on='Link_ID')\n",
    "                            data.dropna(inplace=True)\n",
    "                            print(data.shape)\n",
    "                            data['Variety2'] = data['Variety2'].replace(\"RedLittle\",\"Red\")\n",
    "                            \n",
    "                            \n",
    "                            path = path_x+level\n",
    "                            for file in os.listdir(path):  \n",
    "                                if (file[0] != 't') & (file[-4:] == '.csv') & (file != '.DS_Store')& (file != 'Icon\\r'):  \n",
    "                                    print(file)    \n",
    "                                    data_temp = pd.read_csv(path+'/'+file)\n",
    "                                    \n",
    "                                    data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                    A = [item for item in SELECTED_FEATURE[level][file_response]]\n",
    "                                    A.insert(0, \"Link_ID\")\n",
    "                                    data_temp = data_temp[A]\n",
    "                                    data_temp.rename(columns={'Unnamed: 0':'Link_ID'}, inplace=True) \n",
    "                                    RD1 = data_temp.drop('Link_ID',axis=1)\n",
    "                                    RD11 = RD1.div(RD1.sum(axis=1), axis=0)\n",
    "                                    data_temp = pd.concat([data_temp['Link_ID'],RD11],axis=1)\n",
    "                                    data_2 = pd.merge(data_temp,data,on='Link_ID')                        \n",
    "                                    data_2.drop(columns = 'Link_ID',inplace=True) \n",
    "                                    data_2.dropna(inplace=True)\n",
    "                                    AL = []\n",
    "                                    for l in range(0,100):\n",
    "                                        data_train,data_val = train_test_split(data_2,train_size=0.95, random_state=l)\n",
    "\n",
    "\n",
    "                                        x_column_list = data_train.drop(columns=['y_b']).columns  \n",
    "                                        #Classification RF \n",
    "\n",
    "                                        pipe = make_pipeline(col_trans, rf_classifier)\n",
    "                                        # Fit on data  \n",
    "                                        pipe.fit(data_train[x_column_list],data_train['y_b'])  \n",
    "                                        y_valid = pipe.predict(data_val[x_column_list])\n",
    "\n",
    "                                        report_All = classification_report(data_val['y_b'],y_valid,output_dict=True)  \n",
    "                                        dAll=pd.DataFrame(report_All).transpose() \n",
    "                                        AL.append(dAll['f1-score'].values)\n",
    "                                    AAA=pd.DataFrame(AL)\n",
    "                                    tRF[k]=AAA.mean() \n",
    "                                    \n",
    "                                    k=k+1  \n",
    "                        tRF.to_excel(writer, sheet_name=level, index=True) \n",
    "        writer.save() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7ccd9",
   "metadata": {},
   "source": [
    "# important_otu+soil+disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "778a46e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 6)\n",
      "(85, 6)\n",
      "(162, 6)\n",
      "(36, 6)\n",
      "(30, 6)\n"
     ]
    }
   ],
   "source": [
    "path_list2 = []\n",
    "#reading files in folder response\n",
    "for root, dirs, files in os.walk(path_response, topdown=False):\n",
    "    for path in dirs:\n",
    "        path_list2.append(path)\n",
    "#reading sheet name       \n",
    "wb = openpyxl.load_workbook(path_response+path+'/feature_selection.xlsx')\n",
    "sheet_list = wb.sheetnames\n",
    "\n",
    "results_dic = dict.fromkeys(sheet_list)\n",
    "\n",
    "for sheet_name in results_dic.keys():\n",
    "    temp_df = pd.DataFrame(columns=path_list2, index=range(0,700))\n",
    "    for folder in path_list2:\n",
    "        data_temp = pd.read_excel(path_response+folder+'/feature_selection.xlsx', sheet_name=sheet_name)\n",
    "        temp_df[folder].iloc[\n",
    "            range(0, len(data_temp['Unnamed: 0'].values))] = data_temp['Unnamed: 0'].values\n",
    "    if sheet_name =='Phylum':\n",
    "        temp_df = temp_df.iloc[range(0,30)]\n",
    "    elif sheet_name =='Class':\n",
    "        temp_df = temp_df.iloc[range(0,36)]\n",
    "    elif sheet_name =='Order':\n",
    "        temp_df = temp_df.iloc[range(0,75)]\n",
    "    elif sheet_name =='Family':\n",
    "        temp_df = temp_df.iloc[range(0,85)]\n",
    "    elif sheet_name =='Genus':\n",
    "        temp_df = temp_df.iloc[range(0,162)]\n",
    "        \n",
    "    results_dic[sheet_name] = temp_df\n",
    "    print( results_dic[sheet_name].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "89cbcef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "(36,)\n",
      "(36,)\n",
      "106\n",
      "7\n",
      "13\n",
      "13\n",
      "15\n",
      "10\n",
      "8\n",
      "Family\n",
      "(85,)\n",
      "(85,)\n",
      "248\n",
      "28\n",
      "27\n",
      "22\n",
      "23\n",
      "30\n",
      "16\n",
      "Genus\n",
      "(162,)\n",
      "(162,)\n",
      "477\n",
      "45\n",
      "45\n",
      "54\n",
      "28\n",
      "53\n",
      "44\n",
      "Order\n",
      "(75,)\n",
      "(75,)\n",
      "219\n",
      "26\n",
      "21\n",
      "19\n",
      "17\n",
      "23\n",
      "16\n",
      "Phylum\n",
      "(30,)\n",
      "(30,)\n",
      "42\n",
      "21\n",
      "21\n",
      "21\n",
      "25\n",
      "20\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "SELECTED_FEATURE = dict.fromkeys(dirs)\n",
    "for col in range(0,len(list_level)):\n",
    "    level = list_level[col]\n",
    "    print(level)\n",
    "    SELECTED_FEATURE[level] = dict.fromkeys(dirs)\n",
    "    response_list = path_list\n",
    "    feature_list = []\n",
    "    for response in response_list:\n",
    "        feature_list.append(all_data[response][level].index.union(results_dic[level][response][results_dic[level][response].notnull()].values))\n",
    "    print(all_data[response][level].index.shape)\n",
    "    print(results_dic[level][response].shape)\n",
    "    feature_list = [item for subitem in feature_list for item in subitem]\n",
    "    feature_list = np.unique(feature_list)\n",
    "    print(len(feature_list))\n",
    "    matrix_df = pd.DataFrame(columns = response_list, index = feature_list)\n",
    "    for response in response_list:\n",
    "        for feature in feature_list:\n",
    "                if (feature in all_data[response][level].index) & (feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 3\n",
    "                elif(feature in all_data[response][level].index) &(feature not in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 2##NetComi\n",
    "                elif (feature not in all_data[response][level].index) &(feature in results_dic[level][response].values):\n",
    "                    matrix_df[response].loc[feature] = 1##ML\n",
    "                else:\n",
    "                    matrix_df[response].loc[feature] = 0##NotMLnotNetcomi   \n",
    "        SELECTED_FEATURE[level][response] = matrix_df[response][matrix_df[response]==3].index\n",
    "        print(SELECTED_FEATURE[level][response].shape[0])\n",
    "    matrix_df['Sum'] = 0\n",
    "    for index in matrix_df.index:\n",
    "        matrix_df['Sum'].loc[index] = sum(matrix_df.loc[index].values)\n",
    "    \n",
    "    matrix_df.sort_values(by='Sum', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f60970",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = datetime.now()\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
