{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfaa63e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading MNIST training set\n",
      "└ @ Main In[4]:11\n",
      "┌ Info: Dividing and grouping training set into batches\n",
      "└ @ Main In[4]:28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Loading MNIST testing set\n",
      "└ @ Main In[4]:38\n"
     ]
    }
   ],
   "source": [
    "using Flux, Flux.Data.MNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON\n",
    "\n",
    "# This cell import the MNIST dataset and group and divide the training images \n",
    "# and labels into small batchs. It also group the images and labels of the \n",
    "# testing set.\n",
    "\n",
    "# Load MNIST set with label and image\n",
    "@info(\"Loading MNIST training set\")\n",
    "train_labels = MNIST.labels()\n",
    "train_imgs = MNIST.images()\n",
    "\n",
    "# group img and labels into small batches\n",
    "# idxs: all the index contained in this batch\n",
    "function make_minibatch(img, label, idxs)\n",
    "    img_batch = Array{Float32}(undef, size(img[1])..., 1, length(idxs))\n",
    "    # copy the ith img into the img_batch variable\n",
    "    for i in 1:length(idxs)\n",
    "        img_batch[:, :, :, i] = Float32.(img[idxs[i]])\n",
    "    end\n",
    "    # match the label of all indices in 0 to 9\n",
    "    label_batch = onehotbatch(label[idxs], 0:9)\n",
    "    return (img_batch, label_batch)\n",
    "end\n",
    "\n",
    "@info(\"Dividing and grouping training set into batches\")\n",
    "# each batch has 128 samples\n",
    "batch_size = 128\n",
    "# divide 60000 samples into 128 each, result in 469 training sets\n",
    "# partition is basically an iterator that divide things into equal parts\n",
    "mb_idxs = partition(1:length(train_imgs), batch_size)\n",
    "train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs]\n",
    "\n",
    "# load test sets and combine imgs and labels into one structure\n",
    "# here we are not dividing the sets into smaller batches \n",
    "@info(\"Loading MNIST testing set\")\n",
    "test_imgs = MNIST.images(:test)\n",
    "test_labels = MNIST.labels(:test)\n",
    "test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs))\n",
    "\n",
    "# now each train/test set is a tuple with a 4d float array and a onehot matrix\n",
    "println(\"Loading dataset...Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85feb76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training image is of type: Array{ColorTypes.Gray{FixedPointNumbers.Normed{UInt8,8}},2}\n",
      "The training label is of type: Int64\n",
      "The training batch is of type: Array{Tuple{Array{Float32,4},Flux.OneHotMatrix{Array{Flux.OneHotVector,1}}},1}\n",
      "The dimension of the image part in one batch: (28, 28, 1, 128)\n",
      "The dimension of the label part in one batch: (10, 128)\n"
     ]
    }
   ],
   "source": [
    "# Examine the dataset here, make sure I understand it\n",
    "\n",
    "# each training image sample is literally an image, encoded with a 2d array\n",
    "println(\"The training image is of type: \",typeof(train_imgs[1]))\n",
    "# each training label is just a number of 0-1 indicating the number of the image\n",
    "println(\"The training label is of type: \",typeof(train_labels[1]))\n",
    "\n",
    "# the type of our training batch\n",
    "# the whole set is a tuple of a 4d array and a onehot matrix, with 469 batches\n",
    "println(\"The training batch is of type: \",typeof(train_set))\n",
    "# further examine the 2 part of the batch\n",
    "# each image is 28*28*1*128\n",
    "# 28*28 stands for the pixals \n",
    "# 1 stands for the channel(common channel is 3 for RGB, but here it's just gray)\n",
    "# 128 stands for the batch size\n",
    "println(\"The dimension of the image part in one batch: \", size(train_set[1][1]))\n",
    "# the dimension of the label part is 10*128\n",
    "# 10 is the label 0-9, in boolean type, where the ith boolean is true for label i\n",
    "# 128 is the batch size\n",
    "println(\"The dimension of the label part in one batch: \", size(train_set[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7390f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: CNN model construction\n",
      "└ @ Main In[25]:6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(Conv((3, 3), 1=>16, relu), #17, Conv((3, 3), 16=>32, relu), #18, Conv((3, 3), 32=>32, relu), #19, #20, Dense(288, 10), softmax)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the CNN model, here I follow how most examples of MNIST by using 3 levels of\n",
    "# convelutions, using ReLU and maxpooling in a 2*2 grid, then flatten it to feed into \n",
    "# the NN model with a softmax activation function. Everything here is pretty standard\n",
    "\n",
    "# Chain collects multiple layers/functions to be called on a given input\n",
    "@info(\"CNN model construction\")\n",
    "model = Chain(\n",
    "    # First convolution\n",
    "    # (3,3) refers to a 3*3 filter, 1=>16 transform 1 channel to 16 for each digit samples\n",
    "    # pad(1,1) add 1 layer of zeros around the input, thus prevent losing pixels when doing\n",
    "    # convolution, this preserve the output as 28*28\n",
    "    # The stride is not set here, I believe the default is simply 1\n",
    "    # ReLU is a standard function for convolution layer, in Flux it is max(0, x)\n",
    "    # This conv() should produce a 28*28*16*128 output for each batch\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    # Maxpool select the largest value in a 2*2 window slide through the original input\n",
    "    # This would reduce the dimension of the pixels to half\n",
    "    # So the output of this layer is 14*14*16*128\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Second convolution\n",
    "    # Basically the same as the first layer increasing the channel from 16 to 32\n",
    "    # produce a 14*14*32*128 output\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    # produce a 7*7*32*128 output\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # Third convolution and pooling, reduce the size to half and leave others unchanged\n",
    "    # So the output here is 3*3*32*128\n",
    "    Conv((3, 3), 32=>32, pad=(1,1), relu),\n",
    "    x -> maxpool(x, (2,2)),\n",
    "\n",
    "    # flatten the 3*3*32*128 input for each batch to 288*128, 288 is the input for a \n",
    "    # traditional NN for each image.\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    \n",
    "    # Just the dense layer in NN models that takes 288 inputs from previous layer and output \n",
    "    # the 10 classifications for all 128 samples in this batch\n",
    "    Dense(288, 10),\n",
    "\n",
    "    # the activation function max(0, x), x being the output of all 10 classifications.\n",
    "    softmax,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd115db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Beginning training loop...\n",
      "└ @ Main In[28]:28\n",
      "WARNING: ChainRulesCore.Zero is deprecated, use ZeroTangent instead.\n",
      "  likely near /home/send_fuze/.julia/packages/IJulia/e8kqU/src/kernel.jl:53\n",
      "WARNING: ChainRulesCore.Composite is deprecated, use Tangent instead.\n",
      "  likely near /home/send_fuze/.julia/packages/IJulia/e8kqU/src/kernel.jl:53\n"
     ]
    }
   ],
   "source": [
    "# This part apply the CNN model defined above and do the actually training and also \n",
    "# calculate the loss and accuracy.\n",
    "\n",
    "# It seems it is a common practice to load the sets into gpu\n",
    "train_set = gpu.(train_set)\n",
    "test_set = gpu.(test_set)\n",
    "model = gpu(model)\n",
    "\n",
    "# precompile the model\n",
    "model(train_set[1][1])\n",
    "\n",
    "# here use crossentropy to calculate the loss between predicted value and the true value\n",
    "function loss(x, y)\n",
    "    # The reference I read added a small amount of gaussian noise to x enhance robustness\n",
    "    # I'm not sure why we need to do this, but it does lead to better results.\n",
    "    x_aug = x .+ 0.1f0*gpu(randn(eltype(x), size(x)))\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end\n",
    "\n",
    "# .== is the vector operator, similar to ==, since onecold is in vector form\n",
    "# This compares the percentage of true prediction\n",
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))\n",
    "\n",
    "# use Adam optimizer here with learning rate of 0.001\n",
    "opt = ADAM(0.001)\n",
    "\n",
    "@info(\"Beginning training loop...\")\n",
    "# record the best accuracy so far\n",
    "best_acc = 0.0\n",
    "# record the last epoch when the accuracy improve to avoid overfitting\n",
    "last_improvement = 0\n",
    "# run all training data 100 times at maximum\n",
    "# Note: in case I forgot later, an epoch means run all training data once\n",
    "for epoch_idx in 1:100\n",
    "    # make those variables global for easier access\n",
    "    global best_acc, last_improvement\n",
    "    # Train for a single epoch\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "\n",
    "    # Calculate accuracy:\n",
    "    acc = accuracy(test_set...)\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch_idx, acc))\n",
    "    \n",
    "    # If our accuracy is good enough, quit out.\n",
    "    if acc >= 0.999\n",
    "        @info(\"Reached our target accuracy of 99.9%...terminate.\")\n",
    "        break\n",
    "    end\n",
    "\n",
    "    # If this is the best accuracy we've seen so far, save the model in BSON\n",
    "    if acc >= best_acc\n",
    "        @info(\"New best accuracy! Saving model out to mnist_conv.bson\")\n",
    "        BSON.@save \"mnist_conv.bson\" model epoch_idx acc\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # If we haven't seen improvement in 5 epochs, drop our learning rate by a factor of 10\n",
    "    if epoch_idx - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\"Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "        # After dropping learning rate, give it a few epochs to improve\n",
    "        last_improvement = epoch_idx\n",
    "    end\n",
    "\n",
    "    # have not improve accuracy for more tha 10 epoch, quit and call it a day\n",
    "    if epoch_idx - last_improvement >= 10\n",
    "        @warn(\"Terminate to prevent overfitting\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.1",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
