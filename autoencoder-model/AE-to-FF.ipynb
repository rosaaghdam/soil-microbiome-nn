{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46fb084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle, params \n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON\n",
    "using CSV\n",
    "using DataFrames\n",
    "using Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04ef47e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@load \"AENN_4.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "662a7aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_fold (generic function with 2 methods)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function divide the data into 10 part and combine the otu with labels\n",
    "# and return them in a batch\n",
    "# So each batch has 22 tuples of 50 otus and an encoded label\n",
    "function make_fold(data, label, idx)\n",
    "    # batch for otu, 100*22\n",
    "    data_batch = Array{Float32, 2}(undef, length(idx), length(data[1,:]))\n",
    "    for i in 1:length(idx)\n",
    "        data_batch[i,:] = data[idx[i],:]\n",
    "    end\n",
    "    # batch for label, 1(onehot encoding)*22\n",
    "    label_batch = onehotbatch(label[idx], 0:1)\n",
    "    return (data_batch', label_batch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30f5295e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "k_fold_partition (generic function with 2 methods)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we have very small amount of dataset,I am going to use 10-fold validation here\n",
    "function k_fold_partition(data, label)\n",
    "    # partition the whole dataset into 10 folds\n",
    "    fold_idx = partition(1:length(data[:,1]), length(data[:,1])÷10+1)\n",
    "    # call make_fold and store the 10 folds\n",
    "    whole_set = [make_fold(data, label, i) for i in fold_idx]\n",
    "\n",
    "    return whole_set\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1df6bbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Feed-Forward NN construction\n",
      "└ @ Main In[64]:2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dense(4 => 4, relu),                  \u001b[90m# 20 parameters\u001b[39m\n",
       "  Dense(4 => 4, relu),                  \u001b[90m# 20 parameters\u001b[39m\n",
       "  Dense(4 => 2),                        \u001b[90m# 10 parameters\u001b[39m\n",
       "  NNlib.softmax,\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m50 parameters, 584 bytes."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model construction\n",
    "@info(\"Feed-Forward NN construction\")\n",
    "ff_model = Chain(\n",
    "    # Input 100 predictors and feed into 52 neurons in the hidden layer\n",
    "    # use ReLu as activation function\n",
    "    Dense(4, 4, relu),\n",
    "    Dense(4, 4, relu),\n",
    "    Dense(4, 2),\n",
    "    softmax\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ba0e89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train (generic function with 1 method)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model in this cell\n",
    "function train(whole_set)\n",
    "    # record the accuracy for each folder\n",
    "    mean_accuracy = zeros(Float32,10)\n",
    "    # loop for 10 folds\n",
    "    for k in 1:10\n",
    "        # set the kth folder as testing set\n",
    "        train_set = whole_set[Not(k)]\n",
    "        test_set = whole_set[k]\n",
    "        best_acc = 0.0\n",
    "        # reset all the parameters\n",
    "        Flux.loadparams!(ff_model, map(p -> p .= randn.(), Flux.params(ff_model)))\n",
    "        # set to terminate the epoches if not improved for too long\n",
    "        last_improvement = 0\n",
    "        # crossentropy as loss function\n",
    "        loss(x, y) = crossentropy(ff_model(x),y)\n",
    "        # take mean of accuracy\n",
    "        accuracy(x, y) = mean(onecold(ff_model(x)) .== onecold(y))\n",
    "        # when learning rate is larger(0.1), the accuracy is far worse and some time result in the\n",
    "        # same value with different input\n",
    "        # when it's smaller(0.001), the result does not differ much\n",
    "        opt = ADAM(0.01)\n",
    "        # 100 epoches for each folder\n",
    "        for epoch_idx in 1:200\n",
    "            Flux.train!(loss, Flux.params(ff_model), train_set, opt)\n",
    "            acc = accuracy(test_set...)\n",
    "            #println(\"Current folder: \", k, \", Epoch: \", epoch_idx, \", Accuracy: \", acc)\n",
    "            if acc >= 0.999\n",
    "                best_acc = acc\n",
    "                break\n",
    "            end\n",
    "            # update the best accuracy and last improvement\n",
    "            if acc >= best_acc\n",
    "                best_acc = acc\n",
    "                last_improvement = epoch_idx\n",
    "            end\n",
    "            # no improvement for too long\n",
    "            if epoch_idx - last_improvement >= 20 && opt.eta > 1e-6\n",
    "                opt.eta /= 10.0\n",
    "                # After dropping learning rate, give it a few epochs to improve\n",
    "                last_improvement = epoch_idx\n",
    "            end\n",
    "            if epoch_idx - last_improvement >= 50\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "        # save the best accuracy for this folder\n",
    "        mean_accuracy[k] = best_acc\n",
    "    end\n",
    "    # output the average accuracy for 10 folders\n",
    "    return mean(mean_accuracy)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc525c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Finish loading the data...\n",
      "└ @ Main In[66]:6\n"
     ]
    }
   ],
   "source": [
    "data = CSV.read(\"../processed-data/otu-yield-per-plant.csv\", DataFrame)\n",
    "data_arr = Matrix(data)\n",
    "# only select the OTUs\n",
    "otu = data_arr[:, 2:2395]\n",
    "label = data_arr[:, 2396]\n",
    "@info(\"Finish loading the data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3db25496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Finish running the AE model \n",
      "└ @ Main In[67]:5\n"
     ]
    }
   ],
   "source": [
    "code = Array{Float32}(undef, 216, 4)\n",
    "for i in 1:length(general_info[:,1])\n",
    "    code[i,:] .= model[1](otu[i,:])\n",
    "end\n",
    "@info (\"Finish running the AE model \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d89ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy is 0.72424245\n"
     ]
    }
   ],
   "source": [
    "# split the dataset into 10 folds\n",
    "whole_set = k_fold_partition(code, label)\n",
    "accuracy = train(whole_set)\n",
    "println(\"The mean accuracy is \", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
